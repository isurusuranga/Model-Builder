{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.applications import vgg16\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Input, Dense, GlobalAveragePooling2D, Merge, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from random import shuffle\n",
    "from scipy.misc import imresize\n",
    "import itertools\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetFeatureExtractor(object):\n",
    "    def __init__(self, model=\"vgg16\", resize_to=(224, 224)):\n",
    "        # MODEL_DICT = {\"vgg16\": VGG16, \"vgg19\": VGG19, \"inception\": InceptionV3, \"resnet\": ResNet50,\n",
    "        #               \"xception\": Xception}\n",
    "        # network = MODEL_DICT[model.lower()]\n",
    "        self.model_name = model.lower()\n",
    "        self.model = self.getModel()\n",
    "        self.preprocess_input = preprocess_input\n",
    "        self.imageSize = resize_to\n",
    "\n",
    "    def extract(self, images):\n",
    "        images = self.preprocess(images)\n",
    "        return self.model.predict(images)\n",
    "\n",
    "    def getModel(self):\n",
    "        model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(\"block5_pool\").output)\n",
    "\n",
    "        return intermediate_layer_model\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self.model.compute_output_shape([[None, self.imageSize[0], self.imageSize[1], 3]])\n",
    "\n",
    "    def resize_images(self, images):\n",
    "        images = np.array([cv2.resize(image, (self.imageSize[0], self.imageSize[1])) for image in images])\n",
    "        return images\n",
    "\n",
    "    def preprocess(self, images):\n",
    "        images = self.resize_images(images)\n",
    "        images = self.preprocess_input(images.astype(\"float\"))\n",
    "        return images\n",
    "\n",
    "def concat_tensors(tensors, axis=-1):\n",
    "    return K.concatenate([K.expand_dims(t, axis=axis) for t in tensors])\n",
    "\n",
    "\n",
    "def get_small_network(input_shape=(None, 4, 4, 512)):\n",
    "    model = Sequential()\n",
    "    model.add(GlobalAveragePooling2D(input_shape=input_shape[1:]))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    #model.add(Dense(128, activation=\"relu\"))\n",
    "    return model\n",
    "\n",
    "def get_triplet_network(input_shape=(None, 4, 4, 512)):\n",
    "    base_model = get_small_network(input_shape=input_shape)\n",
    "\n",
    "    anchor_input = Input(input_shape[1:])\n",
    "    positive_input = Input(input_shape[1:])\n",
    "    negative_input = Input(input_shape[1:])\n",
    "\n",
    "    anchor_embeddings = base_model(anchor_input)\n",
    "    positive_embeddings = base_model(positive_input)\n",
    "    negative_embeddings = base_model(negative_input)\n",
    "\n",
    "    output = Lambda(concat_tensors)([anchor_embeddings, positive_embeddings, negative_embeddings])\n",
    "    model = Model([anchor_input, positive_input, negative_input], output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(data, labels):\n",
    "    pos_label, neg_label = np.random.choice(labels, 2, replace=False)\n",
    "    pos_indexes = np.where(labels == pos_label)[0]\n",
    "    neg_indexes = np.where(labels == neg_label)[0]\n",
    "    np.random.shuffle(pos_indexes)\n",
    "    np.random.shuffle(neg_indexes)\n",
    "    anchor = data[pos_indexes[0]]\n",
    "    positive = data[pos_indexes[-1]]\n",
    "    negative = data[neg_indexes[0]]\n",
    "    return (anchor, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_neg(anchor, embeddings, mask):\n",
    "    embeddings_masked = embeddings * mask\n",
    "    distances = tf.norm(anchor-embeddings_masked)\n",
    "    dist_idx  = tf.argmin(distances)\n",
    "    return dist_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_hard_negative_triplet_loss(labels, embeddings):\n",
    "\n",
    "    margin = 1\n",
    "    feat_size = 512\n",
    "    num_identities = 6\n",
    "    samples_per_id = 20\n",
    "\n",
    "    triplet_list = []\n",
    "    pos_dist_list, neg_dist_list = [], []\n",
    "\n",
    "    for i in range(num_identities * samples_per_id):\n",
    "        anchor = embeddings[i]\n",
    "        mask = tf.logical_not(tf.equal(labels[i], labels))\n",
    "        mask = tf.expand_dims(mask, 1)\n",
    "        anchor_tiled = tf.tile([anchor], [num_identities * samples_per_id, 1])\n",
    "        hard_neg = get_hard_neg(anchor_tiled, embeddings, mask)\n",
    "        mult = (i // samples_per_id)+1 \n",
    "        for j in range(i+1,samples_per_id*mult):\n",
    "            triplet_list += [(anchor, embeddings[j], embeddings[hard_neg])]\n",
    "\n",
    "    triplets = tf.stack(triplet_list)\n",
    "    \n",
    "    for i in range(num_identities * (samples_per_id * (samples_per_id-1)) // 2):\n",
    "        pos_dist_list += [tf.norm(triplets[i,0] - triplets[i,1])]\n",
    "        neg_dist_list += [tf.norm(triplets[i,0] - triplets[i,2])]\n",
    "\n",
    "    pos_dist = tf.stack(pos_dist_list)\n",
    "    neg_dist = tf.stack(neg_dist_list)\n",
    "\n",
    "    triplet_loss = tf.reduce_mean(tf.maximum(pos_dist - neg_dist + margin, 0.))\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triples(image_dir):\n",
    "    img_groups = {}\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        prefix, suffix = img_file.split(\".\")\n",
    "        gid, pid = prefix[0:4], prefix[4:]\n",
    "        if img_groups.has_key(gid):\n",
    "            img_groups[gid].append(pid)\n",
    "        else:\n",
    "            img_groups[gid] = [pid]\n",
    "    pos_triples, neg_triples = [], []\n",
    "    # positive pairs are any combination of images in same group\n",
    "    for key in img_groups.keys():\n",
    "        triples = [(key + x[0] + \".jpg\", key + x[1] + \".jpg\", 1) \n",
    "                 for x in itertools.combinations(img_groups[key], 2)]\n",
    "        pos_triples.extend(triples)\n",
    "    # need equal number of negative examples\n",
    "    group_names = list(img_groups.keys())\n",
    "    for i in range(len(pos_triples)):\n",
    "        g1, g2 = np.random.choice(np.arange(len(group_names)), size=2, replace=False)\n",
    "        left = get_random_image(img_groups, group_names, g1)\n",
    "        right = get_random_image(img_groups, group_names, g2)\n",
    "        neg_triples.append((left, right, 0))\n",
    "    pos_triples.extend(neg_triples)\n",
    "    shuffle(pos_triples)\n",
    "    return pos_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(hdf5_path):\n",
    "    db = h5py.File(hdf5_path,mode=\"r\")\n",
    "    features = db[\"features\"][:]\n",
    "    labels = db[\"labels\"][:]\n",
    "\n",
    "    return (features, labels)\n",
    "\n",
    "def extract_embeddings(features, model):\n",
    "    embeddings = model.predict([features, features, features])\n",
    "    return embeddings[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check_point_loc = 'C:/Users/hp/Downloads/data/similarity/vgg16_cats_dogs_sm.h5'\n",
    "features, labels = extract_features('C:/Users/hp/Downloads/data/similarity/similarity_db.hdf5')\n",
    "\n",
    "model = get_triplet_network(features.shape)\n",
    "\n",
    "#model.compile(optimizer=optimizers.Adam(lr=1e-4), loss=batch_hard_negative_triplet_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 4, 4, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
