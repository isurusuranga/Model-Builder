{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import applications\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras import Model\n",
    "from keras import initializers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import layer_utils, np_utils\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from classification_models import ResNet18\n",
    "from classification_models.resnet import preprocess_input as resnet_preprocess_input\n",
    "from keras.applications.densenet import preprocess_input as densenet_preprocess_input\n",
    "from keras.applications.vgg16 import preprocess_input as vgg_preprocess_input\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "feature_scaler_filename = \"D:/retinal_data_set_visioncare/Image_Retrieval/feature_scaler.save\"\n",
    "svd_scaler_file_name = \"D:/retinal_data_set_visioncare/Image_Retrieval/svd_scaler.save\"\n",
    "file_path = 'D:/retinal_data_set_visioncare/Image_Retrieval/img_database.csv'\n",
    "\n",
    "densenet_base = applications.DenseNet201(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
    "resnet_base = ResNet18(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
    "vgg_base = applications.VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_x = densenet_base.get_layer(index=-1).output\n",
    "densenet_feature_extraction_layer = GlobalAveragePooling2D()(densenet_x)\n",
    "densenet_model = Model(inputs=densenet_base.input, outputs=densenet_feature_extraction_layer)\n",
    "densenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_x = resnet_base.get_layer(index=-1).output\n",
    "resnet_feature_extraction_layer = GlobalAveragePooling2D()(resnet_x)\n",
    "resnet_model = Model(inputs=resnet_base.input, outputs=resnet_feature_extraction_layer)\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_x = vgg_base.get_layer(index=-1).output\n",
    "vgg_feature_extraction_layer = GlobalAveragePooling2D()(vgg_x)\n",
    "vgg_model = Model(inputs=vgg_base.input, outputs=vgg_feature_extraction_layer)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a compiled model identical to the previous one\n",
    "loaded_pretrained_deep_feature_model = load_model('D:/retinal_data_set_visioncare/models/ensemble/densenet_deep_feature_with_SVD_dr.h5')\n",
    "loaded_pretrained_deep_feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_layer = loaded_pretrained_deep_feature_model.get_layer('activation_25').output\n",
    "feature_extract_model = Model(inputs=loaded_pretrained_deep_feature_model.input, outputs=feature_extraction_layer)\n",
    "feature_extract_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a compiled model identical to the previous one\n",
    "loaded_deep_hash_model = load_model('D:/retinal_data_set_visioncare/Image_Retrieval/deep_hash_model.h5')\n",
    "loaded_deep_hash_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashcode_extraction_layer = loaded_deep_hash_model.get_layer('activation_5').output\n",
    "hashcode_extract_model = Model(inputs=loaded_deep_hash_model.input, outputs=hashcode_extraction_layer)\n",
    "hashcode_extract_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_scalar = joblib.load(feature_scaler_filename) \n",
    "norm_truncated_opt_svd = joblib.load(svd_scaler_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve deep hash code for a given query image\n",
    "def get_deep_feature_hashcode_for_query_img(source):\n",
    "    source = retina_root + relative_path\n",
    "    img = image.load_img(source, target_size=(image_width, image_height))\n",
    "    img_x = image.img_to_array(img)\n",
    "    img_x = np.expand_dims(img_x, axis=0)\n",
    "\n",
    "    # densenet201 - feature extraction\n",
    "    densenet201_x = densenet_preprocess_input(img_x)\n",
    "    densenet201_extract_features = densenet_model.predict(densenet201_x)\n",
    "    flattern_feature_vector = densenet201_extract_features.flatten()\n",
    "\n",
    "    # resnet18 - feature extraction\n",
    "    resnet18_x = resnet_preprocess_input(img_x)\n",
    "    resnet18_extract_features = resnet_model.predict(resnet18_x)\n",
    "    resnet18_feature_vector = resnet18_extract_features.flatten()\n",
    "\n",
    "    # vgg16 - feature extraction\n",
    "    vgg16_x = vgg_preprocess_input(img_x)\n",
    "    vgg16_extract_features = vgg_model.predict(vgg16_x)\n",
    "    vgg16_feature_vector = vgg16_extract_features.flatten()\n",
    "\n",
    "    flattern_feature_vector = np.concatenate((flattern_feature_vector, resnet18_feature_vector, vgg16_feature_vector))\n",
    "    scaled_flattern_feature_vector = norm_scalar.transform(np.array([flattern_feature_vector]))\n",
    "    transformed_flattern_feature_vector = norm_truncated_opt_svd.transform(scaled_flattern_feature_vector)\n",
    "    ensemble_compressed_feature = feature_extract_model.predict(transformed_flattern_feature_vector)\n",
    "    ensemble_compressed_feature_np = np.array([ensemble_compressed_feature.flatten()])\n",
    "    deep_feature = [val for val in ensemble_compressed_feature.flatten()]\n",
    "    # load feature extractor model for sigmoid layer model as a feature extractor\n",
    "    deep_hash_proba = hashcode_extract_model.predict(ensemble_compressed_feature_np)\n",
    "    deep_hash_code = [1 if val >= 0.5 else 0 for val in deep_hash_proba.flatten()]\n",
    "\n",
    "    return deep_feature, deep_hash_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_similarity_score(row_hash_code, query_hashcode):\n",
    "    jaccard_sim = jaccard_similarity_score(row_hash_code, query_hashcode)\n",
    "    return jaccard_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity_score(row_deep_feature, query_feature):\n",
    "    cosine_sim = 1 - spatial.distance.cosine(row_deep_feature, query_feature)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming distance with hashcodes in database\n",
    "# load csv and compare\n",
    "dataset = pd.read_csv(file_path, delimiter=',', converters=dict(deep_features=literal_eval, hash_code=literal_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>deep_features</th>\n",
       "      <th>hash_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/retinal_data_set_visioncare/New_Train_Test_...</td>\n",
       "      <td>[[0.         0.2817384  0.17564283 0.16437872 ...</td>\n",
       "      <td>[0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/retinal_data_set_visioncare/New_Train_Test_...</td>\n",
       "      <td>[[0.         0.         0.35064828 0.20183267 ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/retinal_data_set_visioncare/New_Train_Test_...</td>\n",
       "      <td>[[0.         0.         0.         0.03911216 ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/retinal_data_set_visioncare/New_Train_Test_...</td>\n",
       "      <td>[[0.         0.20498309 0.         0.12469342 ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/retinal_data_set_visioncare/New_Train_Test_...</td>\n",
       "      <td>[[0.         0.34591606 0.22904815 0.13837777 ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  \\\n",
       "0  D:/retinal_data_set_visioncare/New_Train_Test_...   \n",
       "1  D:/retinal_data_set_visioncare/New_Train_Test_...   \n",
       "2  D:/retinal_data_set_visioncare/New_Train_Test_...   \n",
       "3  D:/retinal_data_set_visioncare/New_Train_Test_...   \n",
       "4  D:/retinal_data_set_visioncare/New_Train_Test_...   \n",
       "\n",
       "                                       deep_features  \\\n",
       "0  [[0.         0.2817384  0.17564283 0.16437872 ...   \n",
       "1  [[0.         0.         0.35064828 0.20183267 ...   \n",
       "2  [[0.         0.         0.         0.03911216 ...   \n",
       "3  [[0.         0.20498309 0.         0.12469342 ...   \n",
       "4  [[0.         0.34591606 0.22904815 0.13837777 ...   \n",
       "\n",
       "                                           hash_code  \n",
       "0  [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, ...  \n",
       "1  [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "2  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, ...  \n",
       "3  [1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "4  [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve deep fature and deep hashcode for query image\n",
    "query_img_path = 'D:/retinal_data_set_visioncare/New_Train_Test_Data/train/3/3444_right.jpeg'\n",
    "query_deep_feature, query_deep_hash_code = get_deep_feature_hashcode_for_query_img(query_img_path)\n",
    "\n",
    "dataset[\"jaccard_sim\"] = dataset.apply(lambda x: get_jaccard_similarity_score(x['hash_code'], query_deep_hash_code), axis=1)\n",
    "\n",
    "# sort descending order by jaccard_sim and retreive top k=10 images\n",
    "#dataset = dataset.sort_values(by='jaccard_sim', ascending=False).head(10)\n",
    "threshold = 0.5\n",
    "dataset = dataset.loc[dataset['jaccard_sim'] >= threshold]\n",
    "\n",
    "# calculate cosine simmilarity by feature space and again sort by cosine simillarity and retrieve the results\n",
    "dataset[\"cosine_sim\"] = dataset.apply(lambda x: get_cosine_similarity_score(x['deep_features'], query_deep_feature), axis=1)\n",
    "dataset = dataset.sort_values(by='cosine_sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "print(jaccard_similarity_score([1, 1, 0, 0], [1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1       col2\n",
      "0    a  [1, 2, 3]\n",
      "1    b  [4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "txt = \"\"\"col1|col2\n",
    "a|[1,2,3]\n",
    "b|[4,5,6]\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(txt), sep='|', converters=dict(col2=literal_eval))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1       col2  newcolumn\n",
      "0    a  [1, 2, 3]   0.333333\n",
      "1    b  [4, 5, 6]   0.000000\n"
     ]
    }
   ],
   "source": [
    "df['newcolumn'] = df.apply(lambda x: get_jaccard_similarity_score(x['col2'], [1, 1, 1]), axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>newcolumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1       col2  newcolumn\n",
       "0    a  [1, 2, 3]   0.333333\n",
       "1    b  [4, 5, 6]   0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='newcolumn', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "dataSetI = [1, 0, -1]\n",
    "dataSetII = [-1,-1, 0]\n",
    "result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1       col2  newcolumn  new_column\n",
      "0    a  [1, 2, 3]   0.333333    0.925820\n",
      "1    b  [4, 5, 6]   0.000000    0.986928\n"
     ]
    }
   ],
   "source": [
    "df['new_column'] = df.apply(lambda x: get_cosine_similarity_score(x['col2'], [1, 1, 1]), axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1       col2  newcolumn  new_column\n",
      "0    a  [1, 2, 3]   0.333333     0.92582\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "df = df.loc[df['newcolumn'] >= threshold]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
