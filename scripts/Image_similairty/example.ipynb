{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import unicode\n",
    "import h5py\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Input, Dense, GlobalAveragePooling2D, Merge, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from imutils import build_montages\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import tqdm\n",
    "#from annoy import AnnoyIndex\n",
    "import json\n",
    "import PIL\n",
    "from functools import partial, update_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224     # input image size for network\n",
    "margin = 0.3       # margin for triplet loss\n",
    "batch_size = 16    # size of mini-batch\n",
    "num_triplet = 1000 \n",
    "valid_frequency = 100\n",
    "num_epoch = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(data, labels):\n",
    "    pos_label, neg_label = np.random.choice(labels, 2, replace=False)\n",
    "    pos_indexes = np.where(labels == pos_label)[0]\n",
    "    neg_indexes = np.where(labels == neg_label)[0]\n",
    "    np.random.shuffle(pos_indexes)\n",
    "    np.random.shuffle(neg_indexes)\n",
    "    anchor = data[pos_indexes[0]]\n",
    "    positive = data[pos_indexes[-1]]\n",
    "    negative = data[neg_indexes[0]]\n",
    "    return (anchor, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to freeze some portion of a function's arguments\n",
    "def wrapped_partial(func, *args, **kwargs):\n",
    "    partial_func = partial(func, *args, **kwargs)\n",
    "    update_wrapper(partial_func, func)\n",
    "    return partial_func\n",
    "\n",
    "# calculate recall score\n",
    "def recall(y_true, y_pred):\n",
    "    return min(len(set(y_true) & set(y_pred)), 1)\n",
    "\n",
    "# margin triplet loss\n",
    "def margin_triplet_loss(y_true, y_pred, margin, batch_size):\n",
    "    out_a = tf.gather(y_pred, tf.range(0, batch_size, 3))\n",
    "    out_p = tf.gather(y_pred, tf.range(1, batch_size, 3))\n",
    "    out_n = tf.gather(y_pred, tf.range(2, batch_size, 3))\n",
    "    \n",
    "    loss = K.maximum(margin\n",
    "                 + K.sum(K.square(out_a-out_p), axis=1)\n",
    "                 - K.sum(K.square(out_a-out_n), axis=1),\n",
    "                 0.0)\n",
    "    return K.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiHardNegativeSampler:\n",
    "    def __init__(self, pool, batch_size, num_samples):\n",
    "        self.pool = pool\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.resample()\n",
    "        \n",
    "    # sample triplets with semi-hard negatives\n",
    "    def resample(self):        \n",
    "        sample_classes = np.random.choice(np.arange(X_train_user.shape[0]), p=num_images_by_class/num_images_by_class.sum(), size=self.num_samples)\n",
    "\n",
    "        sample_images = []\n",
    "        for i in sample_classes:\n",
    "            sample_images.append(train_images_user[np.random.choice(X_train_user[i].nonzero()[1], replace=False)])\n",
    "            sample_images.append(train_images_seller[np.random.choice(X_train_seller[i].nonzero()[1], replace=False)])\n",
    "        sample_images = np.array(sample_images)\n",
    "\n",
    "        pred_sample = model.predict_generator(batch_generator_predict(pool, 32, sample_images), math.ceil(len(sample_images)/32), max_q_size=1, workers=1)\n",
    "\n",
    "        a = pred_sample[np.arange(0, len(pred_sample), 2)]\n",
    "        p = pred_sample[np.arange(1, len(pred_sample), 2)]\n",
    "        triplets = []\n",
    "        self.dists = []\n",
    "\n",
    "        for i in range(self.num_samples):\n",
    "            d = np.square(a[i] - p[i]).sum()\n",
    "            neg_sample_classes = (sample_classes != sample_classes[i]).nonzero()[0]\n",
    "\n",
    "            neg = p[neg_sample_classes]\n",
    "\n",
    "            neg_ids = sample_images.reshape((-1, 2))[neg_sample_classes, 1]\n",
    "\n",
    "            d_neg = np.square(neg - a[i]).sum(axis=1)\n",
    "\n",
    "            semihard = np.where(d_neg > d)[0]\n",
    "\n",
    "            if len(semihard) == 0:\n",
    "                n = np.argmax(d_neg)\n",
    "            else:\n",
    "                n = semihard[np.argmin(d_neg[semihard])]\n",
    "                \n",
    "            self.dists.append(d_neg[n]-d)\n",
    "\n",
    "            triplets.append(np.concatenate([sample_images.reshape((-1, 2))[i], np.array([neg_ids[n]])]))\n",
    "\n",
    "        self.triplets = np.array(triplets)\n",
    "        \n",
    "    # data generator for triplets\n",
    "    def batch_generator(self):\n",
    "        i = 0\n",
    "        while True:\n",
    "            batch = self.triplets[i:i+self.batch_size//3].ravel()\n",
    "            \n",
    "            i += self.batch_size//3\n",
    "            if len(batch) == 0:\n",
    "                yield np.zeros((0, img_size, img_size, 3))\n",
    "            else:\n",
    "                result = pool.map(preprocess_image_worker_aug, batch)\n",
    "                X_batch = np.concatenate(result, axis=0)\n",
    "                yield X_batch, np.zeros(len(batch))\n",
    "\n",
    "    # return data generator for triplets\n",
    "    def get_generator(self):\n",
    "        gen = self.batch_generator()\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_features(image_paths, labels, hdf5_path, feature_extractor, image_formats=(\"jpg\")):\n",
    "    # image_paths = []\n",
    "    # for image_format in image_formats:\n",
    "    #     image_paths += glob.glob(\"{}/*.{}\".format(images_dir, image_format))\n",
    "    # image_paths = sorted(image_paths)\n",
    "    db = h5py.File(hdf5_path, mode=\"w\")\n",
    "    features_shape = ((len(labels),), feature_extractor.output_shape[1:])\n",
    "    features_shape = [dim for sublist in features_shape for dim in sublist]\n",
    "    imageIDDB = db.create_dataset(\"image_ids\", shape=(len(labels),),\n",
    "                                  dtype=h5py.special_dtype(vlen=unicode))\n",
    "    featuresDB = db.create_dataset(\"features\",\n",
    "                                   shape=features_shape, dtype=\"float\")\n",
    "    labelsDB = db.create_dataset(\"labels\",\n",
    "                                 shape=(len(labels),), dtype=\"int\")\n",
    "    for i in range(0, len(labels), 16):\n",
    "        start,end = i, i+16\n",
    "        image_ids = [path.split(\"/\")[-1] for path in image_paths[start:end]]\n",
    "        images = [cv2.imread(path,1) for path in image_paths[start:end]]\n",
    "        features = feature_extractor.extract(images)\n",
    "        imageIDDB[start:end] = image_ids\n",
    "        featuresDB[start:end] = features\n",
    "        labelsDB[start:end] = labels[start:end]\n",
    "        print(\"Extracting {}/{}\".format(i+1+16, len(labels)))\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(hdf5_path):\n",
    "    db = h5py.File(hdf5_path,mode=\"r\")\n",
    "    features = db[\"features\"][:]\n",
    "    labels = db[\"labels\"][:]\n",
    "\n",
    "    return (features, labels)\n",
    "\n",
    "def extract_embeddings(features, model):\n",
    "    embeddings = model.predict([features, features, features])\n",
    "    return embeddings[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a,b):\n",
    "    return K.sqrt(K.sum(K.square((a-b)), axis=1))\n",
    "\n",
    "def cosine_distance(a, b, normalize=True):\n",
    "    if normalize:\n",
    "        a = K.l2_normalize(a, axis=0)\n",
    "        b = K.l2_normalize(b, axis=0)\n",
    "    return K.prod(K.stack([a, b], axis=1), axis=1)\n",
    "\n",
    "def triplet_loss(y_true, anchor_positive_negative_tensor):\n",
    "    anchor = anchor_positive_negative_tensor[:,:,0]\n",
    "    positive = anchor_positive_negative_tensor[:,:,1]\n",
    "    negative = anchor_positive_negative_tensor[:,:,2]\n",
    "    Dp = euclidean_distance(anchor, positive)\n",
    "    Dn = euclidean_distance(anchor, negative)\n",
    "\n",
    "    return K.maximum(0.0, 1+K.mean(Dp-Dn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetFeatureExtractor(object):\n",
    "    def __init__(self, model=\"vgg16\", resize_to=(150, 150)):\n",
    "        # MODEL_DICT = {\"vgg16\": VGG16, \"vgg19\": VGG19, \"inception\": InceptionV3, \"resnet\": ResNet50,\n",
    "        #               \"xception\": Xception}\n",
    "        # network = MODEL_DICT[model.lower()]\n",
    "        self.model_name = model.lower()\n",
    "        self.model = self.getModel()\n",
    "        self.preprocess_input = preprocess_input\n",
    "        self.imageSize = resize_to\n",
    "\n",
    "    def extract(self, images):\n",
    "        images = self.preprocess(images)\n",
    "        return self.model.predict(images)\n",
    "\n",
    "    def getModel(self):\n",
    "        model = load_model('C:/Users/hp/Downloads/data/model/top_model_vgg/final_model.h5')\n",
    "        intermediate_layer_model = Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer(\"block5_pool\").output)\n",
    "\n",
    "        return intermediate_layer_model\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self.model.compute_output_shape([[None, self.imageSize[0], self.imageSize[1], 3]])\n",
    "\n",
    "    def resize_images(self, images):\n",
    "        images = np.array([cv2.resize(image, (self.imageSize[0], self.imageSize[1])) for image in images])\n",
    "        return images\n",
    "\n",
    "    def preprocess(self, images):\n",
    "        images = self.resize_images(images)\n",
    "        images = self.preprocess_input(images.astype(\"float\"))\n",
    "        return images\n",
    "\n",
    "def concat_tensors(tensors, axis=-1):\n",
    "    return K.concatenate([K.expand_dims(t, axis=axis) for t in tensors])\n",
    "\n",
    "\n",
    "def get_small_network(input_shape=(None, 4, 4, 512)):\n",
    "    model = Sequential()\n",
    "    model.add(GlobalAveragePooling2D(input_shape=input_shape[1:]))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    #model.add(Dense(128, activation=\"relu\"))\n",
    "    return model\n",
    "\n",
    "def get_triplet_network(input_shape=(None, 4, 4, 512)):\n",
    "    base_model = get_small_network(input_shape=input_shape)\n",
    "\n",
    "    anchor_input = Input(input_shape[1:])\n",
    "    positive_input = Input(input_shape[1:])\n",
    "    negative_input = Input(input_shape[1:])\n",
    "\n",
    "    anchor_embeddings = base_model(anchor_input)\n",
    "    positive_embeddings = base_model(positive_input)\n",
    "    negative_embeddings = base_model(negative_input)\n",
    "\n",
    "    output = Lambda(concat_tensors)([anchor_embeddings, positive_embeddings, negative_embeddings])\n",
    "    model = Model([anchor_input, positive_input, negative_input], output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list=[]\n",
    "labels=[]\n",
    "train_data_dir = 'C:/Users/hp/Downloads/data/train/'\n",
    "cat_root = train_data_dir + 'cats' + '/'\n",
    "cats=os.listdir(cat_root)\n",
    "\n",
    "for cat in cats:\n",
    "    image_path_list.append(cat_root + cat)\n",
    "    labels.append(0)\n",
    "\n",
    "dog_root = train_data_dir + 'dogs' + '/'\n",
    "dogs=os.listdir(dog_root)\n",
    "for dog in dogs:\n",
    "    image_path_list.append(dog_root + dog)\n",
    "    labels.append(1)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [cv2.imread(path,1) for path in image_path_list[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 87, 164, 203],\n",
       "         [ 87, 164, 203],\n",
       "         [ 88, 165, 204],\n",
       "         ...,\n",
       "         [122, 201, 240],\n",
       "         [121, 200, 239],\n",
       "         [120, 199, 238]],\n",
       " \n",
       "        [[ 87, 164, 203],\n",
       "         [ 87, 164, 203],\n",
       "         [ 88, 165, 204],\n",
       "         ...,\n",
       "         [123, 202, 241],\n",
       "         [122, 201, 240],\n",
       "         [120, 199, 238]],\n",
       " \n",
       "        [[ 87, 164, 203],\n",
       "         [ 87, 164, 203],\n",
       "         [ 88, 165, 204],\n",
       "         ...,\n",
       "         [123, 202, 241],\n",
       "         [122, 201, 240],\n",
       "         [121, 200, 239]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55, 122, 153],\n",
       "         [ 55, 122, 153],\n",
       "         [ 55, 122, 153],\n",
       "         ...,\n",
       "         [  0,   2,   2],\n",
       "         [  0,   2,   2],\n",
       "         [  0,   2,   2]],\n",
       " \n",
       "        [[ 54, 121, 152],\n",
       "         [ 54, 121, 152],\n",
       "         [ 54, 121, 152],\n",
       "         ...,\n",
       "         [  0,   2,   2],\n",
       "         [  0,   2,   2],\n",
       "         [  0,   2,   2]],\n",
       " \n",
       "        [[ 53, 120, 151],\n",
       "         [ 53, 120, 151],\n",
       "         [ 53, 120, 151],\n",
       "         ...,\n",
       "         [  0,   1,   1],\n",
       "         [  0,   1,   1],\n",
       "         [  0,   1,   1]]], dtype=uint8), array([[[ 40,  44,  39],\n",
       "         [ 40,  44,  39],\n",
       "         [ 43,  44,  40],\n",
       "         ...,\n",
       "         [171, 204, 207],\n",
       "         [164, 199, 202],\n",
       "         [161, 199, 201]],\n",
       " \n",
       "        [[ 41,  45,  40],\n",
       "         [ 41,  45,  40],\n",
       "         [ 43,  44,  40],\n",
       "         ...,\n",
       "         [169, 200, 203],\n",
       "         [161, 196, 199],\n",
       "         [157, 195, 197]],\n",
       " \n",
       "        [[ 41,  45,  40],\n",
       "         [ 41,  45,  40],\n",
       "         [ 43,  44,  40],\n",
       "         ...,\n",
       "         [165, 196, 199],\n",
       "         [162, 195, 198],\n",
       "         [160, 195, 198]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 31,  30,  32],\n",
       "         [ 29,  28,  30],\n",
       "         [ 25,  24,  26],\n",
       "         ...,\n",
       "         [ 17,  23,  36],\n",
       "         [ 24,  30,  43],\n",
       "         [ 40,  46,  57]],\n",
       " \n",
       "        [[ 31,  30,  32],\n",
       "         [ 29,  28,  30],\n",
       "         [ 25,  24,  26],\n",
       "         ...,\n",
       "         [ 21,  29,  42],\n",
       "         [ 25,  33,  46],\n",
       "         [ 36,  45,  55]],\n",
       " \n",
       "        [[ 31,  30,  32],\n",
       "         [ 28,  27,  29],\n",
       "         [ 24,  23,  25],\n",
       "         ...,\n",
       "         [ 30,  38,  51],\n",
       "         [ 23,  31,  44],\n",
       "         [ 21,  30,  40]]], dtype=uint8), array([[[ 39,  30,  26],\n",
       "         [ 37,  28,  24],\n",
       "         [ 32,  23,  19],\n",
       "         ...,\n",
       "         [155, 158, 126],\n",
       "         [154, 157, 125],\n",
       "         [154, 157, 125]],\n",
       " \n",
       "        [[ 42,  33,  29],\n",
       "         [ 42,  33,  29],\n",
       "         [ 39,  30,  26],\n",
       "         ...,\n",
       "         [155, 158, 126],\n",
       "         [154, 157, 125],\n",
       "         [153, 156, 124]],\n",
       " \n",
       "        [[ 43,  34,  30],\n",
       "         [ 47,  38,  34],\n",
       "         [ 48,  39,  35],\n",
       "         ...,\n",
       "         [156, 159, 127],\n",
       "         [155, 158, 126],\n",
       "         [153, 156, 124]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[116, 151, 165],\n",
       "         [114, 149, 163],\n",
       "         [105, 142, 156],\n",
       "         ...,\n",
       "         [  2, 171, 175],\n",
       "         [  3, 167, 172],\n",
       "         [  0, 161, 166]],\n",
       " \n",
       "        [[111, 146, 160],\n",
       "         [110, 145, 159],\n",
       "         [102, 139, 153],\n",
       "         ...,\n",
       "         [  2, 171, 175],\n",
       "         [  3, 167, 172],\n",
       "         [  0, 161, 166]],\n",
       " \n",
       "        [[105, 140, 154],\n",
       "         [105, 140, 154],\n",
       "         [ 99, 136, 150],\n",
       "         ...,\n",
       "         [  2, 171, 175],\n",
       "         [  3, 167, 172],\n",
       "         [  0, 161, 166]]], dtype=uint8), array([[[220, 225, 224],\n",
       "         [219, 224, 223],\n",
       "         [219, 224, 223],\n",
       "         ...,\n",
       "         [249, 242, 245],\n",
       "         [249, 242, 245],\n",
       "         [249, 242, 245]],\n",
       " \n",
       "        [[218, 223, 222],\n",
       "         [218, 223, 222],\n",
       "         [219, 224, 223],\n",
       "         ...,\n",
       "         [251, 244, 247],\n",
       "         [251, 244, 247],\n",
       "         [251, 244, 247]],\n",
       " \n",
       "        [[216, 221, 220],\n",
       "         [217, 222, 221],\n",
       "         [217, 222, 221],\n",
       "         ...,\n",
       "         [252, 246, 247],\n",
       "         [253, 247, 248],\n",
       "         [253, 247, 248]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[224, 215, 211],\n",
       "         [226, 217, 213],\n",
       "         [221, 215, 210],\n",
       "         ...,\n",
       "         [211, 211, 217],\n",
       "         [211, 211, 217],\n",
       "         [211, 211, 217]],\n",
       " \n",
       "        [[224, 215, 211],\n",
       "         [226, 217, 213],\n",
       "         [221, 215, 210],\n",
       "         ...,\n",
       "         [211, 211, 217],\n",
       "         [211, 211, 217],\n",
       "         [211, 211, 217]],\n",
       " \n",
       "        [[224, 215, 211],\n",
       "         [226, 217, 213],\n",
       "         [221, 215, 210],\n",
       "         ...,\n",
       "         [211, 211, 217],\n",
       "         [211, 211, 217],\n",
       "         [211, 211, 217]]], dtype=uint8), array([[[ 75, 112, 140],\n",
       "         [ 75, 112, 140],\n",
       "         [ 79, 116, 144],\n",
       "         ...,\n",
       "         [ 54,  77, 127],\n",
       "         [ 58,  77, 120],\n",
       "         [ 34,  50,  86]],\n",
       " \n",
       "        [[ 71, 108, 136],\n",
       "         [ 72, 109, 137],\n",
       "         [ 78, 115, 143],\n",
       "         ...,\n",
       "         [ 56,  79, 129],\n",
       "         [ 68,  87, 130],\n",
       "         [ 24,  40,  76]],\n",
       " \n",
       "        [[ 53,  88, 114],\n",
       "         [ 55,  90, 116],\n",
       "         [ 63,  98, 124],\n",
       "         ...,\n",
       "         [ 44,  66, 118],\n",
       "         [ 70,  89, 134],\n",
       "         [  6,  22,  59]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  78,  85],\n",
       "         [ 55,  65,  72],\n",
       "         [ 43,  54,  62],\n",
       "         ...,\n",
       "         [ 52,  80,  91],\n",
       "         [ 52,  78,  90],\n",
       "         [ 57,  79,  91]],\n",
       " \n",
       "        [[ 56,  66,  73],\n",
       "         [ 46,  56,  63],\n",
       "         [ 39,  50,  58],\n",
       "         ...,\n",
       "         [ 70,  98, 109],\n",
       "         [ 64,  90, 102],\n",
       "         [ 63,  85,  97]],\n",
       " \n",
       "        [[ 49,  59,  66],\n",
       "         [ 42,  52,  59],\n",
       "         [ 38,  49,  57],\n",
       "         ...,\n",
       "         [ 70,  98, 109],\n",
       "         [ 57,  83,  95],\n",
       "         [ 56,  78,  90]]], dtype=uint8), array([[[ 10,  58,  60],\n",
       "         [ 14,  57,  60],\n",
       "         [ 18,  56,  61],\n",
       "         ...,\n",
       "         [ 15,  14,  10],\n",
       "         [ 12,  11,   7],\n",
       "         [ 47,  46,  42]],\n",
       " \n",
       "        [[  6,  54,  56],\n",
       "         [ 10,  53,  56],\n",
       "         [ 14,  52,  57],\n",
       "         ...,\n",
       "         [ 35,  37,  37],\n",
       "         [ 17,  19,  19],\n",
       "         [ 15,  17,  17]],\n",
       " \n",
       "        [[  4,  49,  52],\n",
       "         [  6,  49,  52],\n",
       "         [ 10,  48,  53],\n",
       "         ...,\n",
       "         [ 19,  25,  30],\n",
       "         [ 13,  19,  24],\n",
       "         [ 15,  21,  26]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[102, 164,  44],\n",
       "         [103, 165,  45],\n",
       "         [104, 166,  46],\n",
       "         ...,\n",
       "         [102, 159,  30],\n",
       "         [100, 158,  26],\n",
       "         [102, 160,  28]],\n",
       " \n",
       "        [[102, 164,  44],\n",
       "         [103, 165,  45],\n",
       "         [103, 165,  45],\n",
       "         ...,\n",
       "         [101, 158,  29],\n",
       "         [ 99, 157,  25],\n",
       "         [100, 158,  26]],\n",
       " \n",
       "        [[102, 164,  44],\n",
       "         [103, 165,  45],\n",
       "         [103, 165,  45],\n",
       "         ...,\n",
       "         [100, 157,  28],\n",
       "         [ 97, 155,  23],\n",
       "         [ 98, 156,  24]]], dtype=uint8), array([[[101, 120, 155],\n",
       "         [102, 121, 156],\n",
       "         [102, 121, 156],\n",
       "         ...,\n",
       "         [117, 136, 174],\n",
       "         [114, 133, 171],\n",
       "         [110, 129, 167]],\n",
       " \n",
       "        [[102, 121, 156],\n",
       "         [103, 122, 157],\n",
       "         [104, 123, 158],\n",
       "         ...,\n",
       "         [119, 138, 176],\n",
       "         [116, 135, 173],\n",
       "         [112, 131, 169]],\n",
       " \n",
       "        [[105, 124, 159],\n",
       "         [106, 125, 160],\n",
       "         [106, 125, 160],\n",
       "         ...,\n",
       "         [121, 140, 178],\n",
       "         [118, 137, 175],\n",
       "         [114, 133, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 53,  72,  99],\n",
       "         [ 52,  71,  98],\n",
       "         [ 51,  70,  97],\n",
       "         ...,\n",
       "         [ 32,  42,  60],\n",
       "         [ 34,  45,  65],\n",
       "         [ 38,  49,  71]],\n",
       " \n",
       "        [[ 53,  72,  99],\n",
       "         [ 52,  71,  98],\n",
       "         [ 51,  70,  97],\n",
       "         ...,\n",
       "         [ 30,  37,  56],\n",
       "         [ 31,  40,  60],\n",
       "         [ 35,  44,  64]],\n",
       " \n",
       "        [[ 53,  72,  99],\n",
       "         [ 53,  72,  99],\n",
       "         [ 51,  70,  97],\n",
       "         ...,\n",
       "         [ 25,  31,  50],\n",
       "         [ 28,  35,  54],\n",
       "         [ 32,  39,  59]]], dtype=uint8), array([[[179, 172, 175],\n",
       "         [176, 169, 172],\n",
       "         [167, 160, 163],\n",
       "         ...,\n",
       "         [201, 193, 194],\n",
       "         [195, 187, 188],\n",
       "         [189, 181, 182]],\n",
       " \n",
       "        [[173, 166, 169],\n",
       "         [171, 164, 167],\n",
       "         [165, 158, 161],\n",
       "         ...,\n",
       "         [183, 177, 178],\n",
       "         [178, 172, 173],\n",
       "         [173, 167, 168]],\n",
       " \n",
       "        [[169, 162, 165],\n",
       "         [171, 164, 167],\n",
       "         [168, 161, 164],\n",
       "         ...,\n",
       "         [190, 183, 186],\n",
       "         [186, 179, 182],\n",
       "         [183, 176, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[175, 156, 129],\n",
       "         [164, 145, 118],\n",
       "         [170, 150, 125],\n",
       "         ...,\n",
       "         [186, 178, 178],\n",
       "         [187, 179, 179],\n",
       "         [188, 180, 180]],\n",
       " \n",
       "        [[177, 159, 136],\n",
       "         [174, 156, 133],\n",
       "         [178, 160, 137],\n",
       "         ...,\n",
       "         [182, 176, 177],\n",
       "         [185, 179, 180],\n",
       "         [188, 182, 183]],\n",
       " \n",
       "        [[182, 165, 144],\n",
       "         [190, 173, 154],\n",
       "         [193, 173, 155],\n",
       "         ...,\n",
       "         [180, 175, 176],\n",
       "         [184, 179, 180],\n",
       "         [189, 184, 185]]], dtype=uint8), array([[[  3,   6,  11],\n",
       "         [  3,   6,  11],\n",
       "         [  3,   6,  11],\n",
       "         ...,\n",
       "         [115, 125, 135],\n",
       "         [121, 131, 141],\n",
       "         [127, 137, 147]],\n",
       " \n",
       "        [[  3,   6,  11],\n",
       "         [  3,   6,  11],\n",
       "         [  3,   6,  11],\n",
       "         ...,\n",
       "         [123, 133, 143],\n",
       "         [128, 138, 148],\n",
       "         [133, 143, 153]],\n",
       " \n",
       "        [[  3,   6,  11],\n",
       "         [  3,   6,  11],\n",
       "         [  3,   6,  11],\n",
       "         ...,\n",
       "         [132, 142, 152],\n",
       "         [135, 145, 155],\n",
       "         [139, 149, 159]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[187, 198, 212],\n",
       "         [184, 195, 209],\n",
       "         [176, 187, 201],\n",
       "         ...,\n",
       "         [ 68,  51,  42],\n",
       "         [ 70,  53,  44],\n",
       "         [ 73,  56,  47]],\n",
       " \n",
       "        [[190, 201, 215],\n",
       "         [192, 203, 217],\n",
       "         [187, 198, 212],\n",
       "         ...,\n",
       "         [ 63,  45,  38],\n",
       "         [ 65,  47,  40],\n",
       "         [ 67,  49,  42]],\n",
       " \n",
       "        [[193, 204, 218],\n",
       "         [194, 205, 219],\n",
       "         [188, 199, 213],\n",
       "         ...,\n",
       "         [ 66,  47,  44],\n",
       "         [ 67,  48,  45],\n",
       "         [ 68,  49,  46]]], dtype=uint8), array([[[ 32,  55,  87],\n",
       "         [ 32,  55,  87],\n",
       "         [ 32,  55,  87],\n",
       "         ...,\n",
       "         [ 49,  71,  96],\n",
       "         [ 49,  71,  96],\n",
       "         [ 49,  71,  96]],\n",
       " \n",
       "        [[ 33,  56,  88],\n",
       "         [ 33,  56,  88],\n",
       "         [ 33,  56,  88],\n",
       "         ...,\n",
       "         [ 43,  68, 100],\n",
       "         [ 43,  68, 100],\n",
       "         [ 43,  68, 100]],\n",
       " \n",
       "        [[ 35,  58,  90],\n",
       "         [ 35,  58,  90],\n",
       "         [ 35,  58,  90],\n",
       "         ...,\n",
       "         [ 35,  67, 108],\n",
       "         [ 35,  67, 108],\n",
       "         [ 35,  67, 108]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 78,  79, 105],\n",
       "         [155, 147, 170],\n",
       "         [149, 130, 149],\n",
       "         ...,\n",
       "         [187, 177, 190],\n",
       "         [186, 176, 189],\n",
       "         [186, 176, 189]],\n",
       " \n",
       "        [[122, 106, 130],\n",
       "         [172, 150, 174],\n",
       "         [ 80,  50,  69],\n",
       "         ...,\n",
       "         [166, 153, 167],\n",
       "         [166, 153, 167],\n",
       "         [167, 154, 168]],\n",
       " \n",
       "        [[181, 161, 184],\n",
       "         [ 78,  51,  71],\n",
       "         [149, 113, 130],\n",
       "         ...,\n",
       "         [173, 160, 174],\n",
       "         [172, 159, 173],\n",
       "         [171, 158, 172]]], dtype=uint8)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ImageNetFeatureExtractor(model='vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Successfully loaded pre-trained model\n",
      "Extracting 17/1200\n",
      "Extracting 33/1200\n",
      "Extracting 49/1200\n",
      "Extracting 65/1200\n",
      "Extracting 81/1200\n",
      "Extracting 97/1200\n",
      "Extracting 113/1200\n",
      "Extracting 129/1200\n",
      "Extracting 145/1200\n",
      "Extracting 161/1200\n",
      "Extracting 177/1200\n",
      "Extracting 193/1200\n",
      "Extracting 209/1200\n",
      "Extracting 225/1200\n",
      "Extracting 241/1200\n",
      "Extracting 257/1200\n",
      "Extracting 273/1200\n",
      "Extracting 289/1200\n",
      "Extracting 305/1200\n",
      "Extracting 321/1200\n",
      "Extracting 337/1200\n",
      "Extracting 353/1200\n",
      "Extracting 369/1200\n",
      "Extracting 385/1200\n",
      "Extracting 401/1200\n",
      "Extracting 417/1200\n",
      "Extracting 433/1200\n",
      "Extracting 449/1200\n",
      "Extracting 465/1200\n",
      "Extracting 481/1200\n",
      "Extracting 497/1200\n",
      "Extracting 513/1200\n",
      "Extracting 529/1200\n",
      "Extracting 545/1200\n",
      "Extracting 561/1200\n",
      "Extracting 577/1200\n",
      "Extracting 593/1200\n",
      "Extracting 609/1200\n",
      "Extracting 625/1200\n",
      "Extracting 641/1200\n",
      "Extracting 657/1200\n",
      "Extracting 673/1200\n",
      "Extracting 689/1200\n",
      "Extracting 705/1200\n",
      "Extracting 721/1200\n",
      "Extracting 737/1200\n",
      "Extracting 753/1200\n",
      "Extracting 769/1200\n",
      "Extracting 785/1200\n",
      "Extracting 801/1200\n",
      "Extracting 817/1200\n",
      "Extracting 833/1200\n",
      "Extracting 849/1200\n",
      "Extracting 865/1200\n",
      "Extracting 881/1200\n",
      "Extracting 897/1200\n",
      "Extracting 913/1200\n",
      "Extracting 929/1200\n",
      "Extracting 945/1200\n",
      "Extracting 961/1200\n",
      "Extracting 977/1200\n",
      "Extracting 993/1200\n",
      "Extracting 1009/1200\n",
      "Extracting 1025/1200\n",
      "Extracting 1041/1200\n",
      "Extracting 1057/1200\n",
      "Extracting 1073/1200\n",
      "Extracting 1089/1200\n",
      "Extracting 1105/1200\n",
      "Extracting 1121/1200\n",
      "Extracting 1137/1200\n",
      "Extracting 1153/1200\n",
      "Extracting 1169/1200\n",
      "Extracting 1185/1200\n",
      "Extracting 1201/1200\n"
     ]
    }
   ],
   "source": [
    "print (\"[+] Successfully loaded pre-trained model\")\n",
    "dump_features(image_path_list, labels=np.array(labels),\n",
    "              hdf5_path='C:/Users/hp/Downloads/data/similarity/similarity_db.hdf5', feature_extractor=feature_extractor,\n",
    "              image_formats=(\"jpg\",\"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check_point_loc = 'C:/Users/hp/Downloads/data/similarity/vgg16_cats_dogs.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Finished loading extracted features\n",
      "Train on 900 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6853 - val_loss: 0.1812\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.5027 - val_loss: 0.0608\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4913 - val_loss: 0.0225\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.7786 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1222 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.6268 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2652 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2103 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1575 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1166 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21da6adea90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = extract_features('C:/Users/hp/Downloads/data/similarity/similarity_db.hdf5')\n",
    "print(\"[+] Finished loading extracted features\")\n",
    "model = get_triplet_network(features.shape)\n",
    "data = []\n",
    "for i in range(len(features)):\n",
    "    anchor, positive, negative = get_triplets(features, labels)\n",
    "    data.append([anchor, positive, negative])\n",
    "data = np.array(data)\n",
    "#  1200 = training examples\n",
    "# 256 = # of features\n",
    "# tripple of images - anchor, positive and negatives = 3\n",
    "targets = np.zeros(shape=(1200, 256, 3))\n",
    "callback = ModelCheckpoint(model_check_point_loc, period=1, monitor=\"val_loss\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, targets)\n",
    "model.compile(optimizers.Adam(1e-4), triplet_loss)\n",
    "model.fit([X_train[:,0], X_train[:,1], X_train[:,2]], Y_train, epochs=10,\n",
    "          validation_data=([X_test[:,0], X_test[:,1], X_test[:,2]], Y_test),\n",
    "          callbacks=[callback], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = h5py.File('C:/Users/hp/Downloads/data/similarity/similarity_db.hdf5', mode=\"r\")[\"image_ids\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_index(imagePath='C:/Users/hp/Downloads/data/train/cats/cat.1.jpg'):\n",
    "    filename = imagePath.split(\"/\")[-1]\n",
    "    return np.where(image_ids == filename)[0][0]\n",
    "\n",
    "def get_image_path(index):\n",
    "    for imagePath in image_path_list:\n",
    "        if imagePath.rsplit('/', 1)[1] == image_ids[index]:\n",
    "            return imagePath\n",
    "    #return args[\"dataset\"].strip(\"/\")+\"/\"+str(image_ids[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(index):\n",
    "    for imagePath in image_path_list:\n",
    "        if imagePath.rsplit('/', 1)[1] == image_ids[index]:\n",
    "            return imagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_check_point_loc, custom_objects={\"triplet_loss\":triplet_loss})\n",
    "features, labels = extract_features('C:/Users/hp/Downloads/data/similarity/similarity_db.hdf5')\n",
    "embeddings = model.predict([features, features, features])\n",
    "embeddings = embeddings[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = get_image_index()\n",
    "query = embeddings[image_id]\n",
    "distances = pairwise_distances(query.reshape(1,-1), embeddings)\n",
    "indices = np.argsort(distances)[0][:12]\n",
    "images = [cv2.imread(get_image_path(index)) for index in indices]\n",
    "images = [cv2.resize(image, (200,200)) for image in images]\n",
    "result = build_montages(images, (200, 200), (4,3))[0]\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.5538974,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 0.       , 12.41322  ,  0.8122095, ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 0.       , 13.904363 ,  3.201221 , ...,  3.0065172,  0.       ,\n",
       "         0.       ],\n",
       "       ...,\n",
       "       [ 9.10835  ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [10.256804 ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [16.977217 ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'C:/Users/hp/Downloads/data/validation/cats/cat.1106.jpg'\n",
    "img = image.load_img(source, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "# get the features \n",
    "extract_features = feature_extractor.getModel().predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = model.predict([extract_features, extract_features, extract_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = test_embedding[:,:,2][0]\n",
    "distances = pairwise_distances(test_query.reshape(1,-1), embeddings)\n",
    "indices = np.argsort(distances)[0][:12]\n",
    "images = [cv2.imread(get_image_path(index)) for index in indices]\n",
    "images = [cv2.resize(image, (200,200)) for image in images]\n",
    "result = build_montages(images, (200, 200), (4,3))[0]\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_image_indices(embeddings, index, num_results=4):\n",
    "    query = embeddings[index]\n",
    "    distances = pairwise_distances(query.reshape(1, -1), embeddings)\n",
    "    indices = np.argsort(distances)[0][:num_results]\n",
    "    return indices\n",
    "\n",
    "def find_num_correct(true_indices, predicted_indices):\n",
    "    num_correct = 0\n",
    "    for i in true_indices:\n",
    "        if i in predicted_indices:\n",
    "            num_correct += 1\n",
    "    return num_correct\n",
    "\n",
    "model = load_model(model_check_point_loc, custom_objects={\"triplet_loss\":triplet_loss})\n",
    "features, labels = extract_features('C:/Users/hp/Downloads/data/similarity/similarity_db.hdf5')\n",
    "embeddings = model.predict([features, features, features])\n",
    "embeddings = embeddings[:,:,2]\n",
    "num_correct = 0\n",
    "\n",
    "for i in range(1200):\n",
    "    similar_indices = get_similar_image_indices(embeddings, i)\n",
    "    true_indices = np.where(labels==(i/4)+1)[0].tolist()\n",
    "    num_correct += find_num_correct(true_indices, similar_indices)/4.0\n",
    "print \"Accuracy\", num_correct/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
