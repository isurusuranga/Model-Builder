{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import Model\n",
    "from keras import initializers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import layer_utils, np_utils\n",
    "from keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sn\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "batch_size = 64\n",
    "\n",
    "train_dir = \"C:/Users/hp/Desktop/Diabetic_retinopathy_dataset_kaggle/original_new/\"\n",
    "\n",
    "vgg16_base = applications.VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = vgg16_base.get_layer(index=-1).output\n",
    "feature_extraction_layer = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=vgg16_base.input, outputs=feature_extraction_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 744 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(image_width, image_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)\n",
    "\n",
    "nb_train_samples = len(train_generator.filenames)  \n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = train_generator.classes  \n",
    "   \n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the predict_generator method returns the output of a model, given\n",
    "# # a generator that yields batches of numpy data\n",
    "# bottleneck_features_train = model.predict_generator(train_generator, nb_train_samples // batch_size + 1)\n",
    "# # save the output as a Numpy array\n",
    "# np.save(open('C:/Users/hp/Desktop/Diabetic_retinopathy_dataset_kaggle/models/vgg16/bottle_neck_features/bottleneck_features_train_without_aug.npy', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_check_point_loc = 'C:/Users/hp/Desktop/Diabetic_retinopathy_dataset_kaggle/models/vgg16/vgg16_deep_feature_kg_without_SVD_dr.h5'\n",
    "# #model_checkpoint = ModelCheckpoint(model_check_point_loc, monitor='val_acc', verbose=0, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open('C:/Users/hp/Desktop/Diabetic_retinopathy_dataset_kaggle/models/vgg16/bottle_neck_features/bottleneck_features_train_without_aug.npy', 'rb'))\n",
    "#test_data = np.load(open('D:/retinal_data_set_visioncare/models/vgg16/bottle_neck_features/bottleneck_features_test_without_aug.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - fature normalizing\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = train_generator.classes  \n",
    "\n",
    "X = X_train\n",
    "Y = train_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight('balanced'\n",
    "                                               ,np.unique(train_data_labels)\n",
    "                                               ,train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.3241830065359477,\n",
       " 1: 1.488,\n",
       " 2: 1.984,\n",
       " 3: 3.381818181818182,\n",
       " 4: 2.2545454545454544}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dic = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 5-fold cross validation test harness\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "kfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=25)\n",
    "cvscores = []\n",
    "trainScores = []\n",
    "f1Score = []\n",
    "num_k_folds = 5\n",
    "fold_counter = 0\n",
    "val_conmats = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f_scores = []\n",
    "input_dim = X_train.shape[1:][0]\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500,max_features=20,max_depth=5,min_samples_leaf=40,criterion=\"gini\", class_weight=class_weight_dic, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averaging the 5-fold results:\n",
      "AVG Train Acc : 81.20%\n",
      "AVG Validation Acc : 69.11%\n",
      "Validation precision - mean: 0.639961, stddev: 0.217146\n",
      "Validation recall - mean: 0.619823, stddev: 0.199361\n",
      "Validation f-score - mean: 0.613703, stddev: 0.191226\n",
      "Confusion matrix:\n",
      "[[70.92 18.6   2.2   0.08  0.  ]\n",
      " [ 9.68  9.12  0.84  0.12  0.24]\n",
      " [ 3.88  2.2   6.44  1.76  0.72]\n",
      " [ 0.08  0.    0.44  5.24  3.04]\n",
      " [ 0.2   0.4   0.24  1.24 11.12]]\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, Y):\n",
    "    # Fit the model\n",
    "    rf_classifier.fit(X[train], Y[train])\n",
    "    \n",
    "    y_train_pred = rf_classifier.predict(X[train])\n",
    "    #y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "    \n",
    "    y_validation_pred = rf_classifier.predict(X[test])\n",
    "    #y_validation_pred = np.argmax(y_validation_pred, axis=1)\n",
    "    #y_validation_pred = np.argmax(y_validation_pred, axis=1)\n",
    "    \n",
    "    [precision, recall, f_score, _] = precision_recall_fscore_support(Y[test], y_validation_pred)\n",
    "    #print(\"Validation k-fold #%d - precision: %f, recallL: %f, f-score: %f\" % (fold_counter, precision, recall, f_score))\n",
    "    \n",
    "    conmat = confusion_matrix(Y[test], y_validation_pred)\n",
    "    \n",
    "    val_precisions.append(precision)\n",
    "    val_recalls.append(recall)\n",
    "    val_f_scores.append(f_score)\n",
    "    val_conmats.append(conmat)\n",
    "    fold_counter = fold_counter + 1\n",
    "    \n",
    "    trainScores.append(accuracy_score(Y[train], y_train_pred))\n",
    "    cvscores.append(accuracy_score(Y[test], y_validation_pred))\n",
    "    \n",
    "print(\"\\nAveraging the 5-fold results:\")\n",
    "print(\"%s: %.2f%%\" % ('AVG Train Acc ', np.mean(trainScores) * 100))\n",
    "print(\"%s: %.2f%%\" % ('AVG Validation Acc ', np.mean(cvscores) * 100))\n",
    "print(\"Validation precision - mean: %f, stddev: %f\" % (np.mean(val_precisions), np.std(val_precisions)))\n",
    "print(\"Validation recall - mean: %f, stddev: %f\" % (np.mean(val_recalls), np.std(val_recalls)))\n",
    "print(\"Validation f-score - mean: %f, stddev: %f\" % (np.mean(val_f_scores), np.std(val_f_scores)))\n",
    "print(\"Confusion matrix:\")\n",
    "print (sum(val_conmats).astype(float) / fold_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
