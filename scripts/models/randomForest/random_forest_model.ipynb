{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils import layer_utils, np_utils\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 10\n",
    "nb_train_samples = 1200 # number of all training samples belong to all possible classses\n",
    "nb_validation_samples = 198 # number of all validation samples belong to all possible classes\n",
    "np_test_samples = 198 # number of all test samples belong to all possible classes\n",
    "#train_dir = \"D:/retinal_data_set_original/_1000_per_class_train/augmented_224/train\"\n",
    "train_dir = \"D:/retinal_data_set_original/original/new_train\"\n",
    "#validation_dir = \"D:/retinal_data_set_original/_1000_per_class_train/augmented_224/validation\"\n",
    "validation_dir = \"D:/retinal_data_set_original/original/new_valid\"\n",
    "test_dir = \"D:/retinal_data_set_original/original/new_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a compiled model identical to the previous one\n",
    "loaded_model = load_model('D:/retinal_data_set_original/original/models/vgg16/vgg16_dr_last2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 21,139,781\n",
      "Trainable params: 6,424,581\n",
      "Non-trainable params: 14,715,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=loaded_model.input,\n",
    "                                 outputs=loaded_model.get_layer(\"dense_13\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               6422784   \n",
      "=================================================================\n",
      "Total params: 21,137,472\n",
      "Trainable params: 6,422,784\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)\n",
    "\n",
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = intermediate_layer_model.predict_generator(train_generator, nb_train_samples // batch_size)\n",
    "# save the output as a Numpy array\n",
    "np.save(open('D:/retinal_data_set_original/original/models/vgg16/bottleneck_features_train_vgg16.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = intermediate_layer_model.predict_generator(validation_generator, nb_validation_samples // batch_size)\n",
    "np.save(open('D:/retinal_data_set_original/original/models/vgg16/bottleneck_features_validation_vgg16.npy', 'wb'), bottleneck_features_validation)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_test = intermediate_layer_model.predict_generator(test_generator, nb_test_samples // batch_size)\n",
    "np.save(open('D:/retinal_data_set_original/original/models/vgg16/bottleneck_features_test_vgg16.npy', 'wb'), bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open('D:/retinal_data_set_original/original/models/vgg16/bottleneck_features_train_vgg16.npy', 'rb'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "\n",
    "train_labels = np.array([0] * 600 + [1] * 600 + [2] * 600 + [3] * 600 + [4] * 600)\n",
    "\n",
    "validation_data = np.load(open('D:/retinal_data_set_original/original/models/vgg16/bottleneck_features_validation_vgg16.npy', 'rb'))\n",
    "validation_labels = np.array([0] * 96 + [1] * 96 + [2] * 96 + [3] * 96 + [4] * 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting n_estimators\n",
    "error_results = []\n",
    "n_estimator_options = [50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "for trees in n_estimator_options:\n",
    "    model = RFC(trees, random_state=1, class_weight=\"balanced\", oob_score=True)\n",
    "    model.fit(train_data, train_labels)\n",
    "    #predict = model.predict(validation_data)\n",
    "    err = 1 - model.score(validation_data,validation_labels)\n",
    "    error_results.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return value in n_estimator_options according to the minimum value index in error_results\n",
    "min_index = error_results.index(min(error_results))\n",
    "num_of_trees = n_estimator_options[min_index]\n",
    "\n",
    "rf = RFC(n_estimators=num_of_trees,max_features=\"sqrt\",max_depth=3,min_samples_leaf=5,criterion=\"gini\",class_weight=\"balanced\")\n",
    "rf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf.predict(validation_data)\n",
    "print (metrics.classification_report(validation_labels, rf_predictions))\n",
    "print (\"Overall Accuracy:\", round(metrics.accuracy_score(validation_labels, rf_predictions), 2))\n",
    "\n",
    "#cross table for test sample\n",
    "preds = rf.predict_proba(validation_data)[:,1]\n",
    "prediction = rf.predict(validation_data)\n",
    "print (pd.crosstab(index=validation_labels, columns=prediction, rownames=['actual'], colnames=['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
