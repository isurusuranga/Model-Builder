{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import Model\n",
    "from keras import initializers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import layer_utils, np_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sn\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "batch_size = 64\n",
    "\n",
    "train_dir = \"D:/retinal_data_set_visioncare/VISION_CARE/\"\n",
    "\n",
    "inceptionv3_base = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = inceptionv3_base.get_layer(index=-1).output\n",
    "feature_extraction_layer = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=inceptionv3_base.input, outputs=feature_extraction_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(image_width, image_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)\n",
    "\n",
    "nb_train_samples = len(train_generator.filenames)  \n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = train_generator.classes  \n",
    "   \n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = model.predict_generator(train_generator, nb_train_samples // batch_size + 1)\n",
    "# save the output as a Numpy array\n",
    "np.save(open('C:/Users/hp/Desktop/Diabetic_retinopathy_dataset_kaggle/models/inceptionV3/bottle_neck_features/bottleneck_features_train_visioncare.npy', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check_point_loc = 'C:/Users/hp/Desktop/Diabetic_retinopathy_dataset_kaggle/models/inceptionV3/inceptionV3_deep_feature_visioncare_without_SVD_dr.h5'\n",
    "#model_checkpoint = ModelCheckpoint(model_check_point_loc, monitor='val_acc', verbose=0, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open('C:/Users/hp/Desktop/Diabetic_retinopathy_dataset_kaggle/models/inceptionV3/bottle_neck_features/bottleneck_features_train_visioncare.npy', 'rb'))\n",
    "#test_data = np.load(open('D:/retinal_data_set_visioncare/models/inceptionV3/bottle_neck_features/bottleneck_features_test_without_aug.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - fature normalizing\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels = train_generator.classes  \n",
    "\n",
    "X = X_train\n",
    "Y = train_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight('balanced'\n",
    "                                               ,np.unique(train_data_labels)\n",
    "                                               ,train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9384615384615385,\n",
       " 1: 1.6636363636363636,\n",
       " 2: 0.4945945945945946,\n",
       " 3: 1.83,\n",
       " 4: 1.3071428571428572}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dic = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 5-fold cross validation test harness\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "kfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=25)\n",
    "cvscores = []\n",
    "trainScores = []\n",
    "f1Score = []\n",
    "num_k_folds = 5\n",
    "fold_counter = 0\n",
    "val_conmats = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f_scores = []\n",
    "input_dim = X_train.shape[1:][0]\n",
    "\n",
    "cross_model = Sequential()\n",
    "cross_model.add(Dense(128, input_dim=input_dim, kernel_initializer=initializers.he_normal(seed=None), kernel_regularizer=regularizers.l2(0.001)))\n",
    "cross_model.add(BatchNormalization())\n",
    "cross_model.add(Activation('relu'))\n",
    "cross_model.add(Dropout(0.8))\n",
    "cross_model.add(Dense(5, kernel_initializer=initializers.he_normal(seed=None), kernel_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l2(0.001)))\n",
    "cross_model.add(BatchNormalization())\n",
    "cross_model.add(Activation('softmax'))\n",
    "\n",
    "cross_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averaging the 5-fold results:\n",
      "AVG Train Acc : 100.00%\n",
      "AVG Validation Acc : 84.64%\n",
      "Validation precision - mean: 0.845816, stddev: 0.173077\n",
      "Validation recall - mean: 0.813295, stddev: 0.234288\n",
      "Validation f-score - mean: 0.814375, stddev: 0.196584\n",
      "Confusion matrix:\n",
      "[[ 7.2   0.28  0.2   0.04  0.08]\n",
      " [ 0.72  2.16  1.48  0.    0.04]\n",
      " [ 0.44  0.4  13.24  0.28  0.44]\n",
      " [ 0.    0.    0.12  3.64  0.24]\n",
      " [ 0.    0.    0.64  0.28  4.68]]\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, Y):\n",
    "    # Fit the model\n",
    "    cross_model.fit(X[train], to_categorical(Y[train]), epochs=400, batch_size=batch_size, class_weight=class_weight_dic, verbose=0)\n",
    "    \n",
    "    y_train_pred = cross_model.predict(X[train])\n",
    "    y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "    \n",
    "    y_validation_pred = cross_model.predict(X[test])\n",
    "    y_validation_pred = np.argmax(y_validation_pred, axis=1)\n",
    "    #y_validation_pred = np.argmax(y_validation_pred, axis=1)\n",
    "    \n",
    "    [precision, recall, f_score, _] = precision_recall_fscore_support(Y[test], y_validation_pred)\n",
    "    #print(\"Validation k-fold #%d - precision: %f, recallL: %f, f-score: %f\" % (fold_counter, precision, recall, f_score))\n",
    "    \n",
    "    conmat = confusion_matrix(Y[test], y_validation_pred)\n",
    "    \n",
    "    val_precisions.append(precision)\n",
    "    val_recalls.append(recall)\n",
    "    val_f_scores.append(f_score)\n",
    "    val_conmats.append(conmat)\n",
    "    fold_counter = fold_counter + 1\n",
    "    \n",
    "    trainScores.append(accuracy_score(Y[train], y_train_pred))\n",
    "    cvscores.append(accuracy_score(Y[test], y_validation_pred))\n",
    "    \n",
    "print(\"\\nAveraging the 5-fold results:\")\n",
    "print(\"%s: %.2f%%\" % ('AVG Train Acc ', np.mean(trainScores) * 100))\n",
    "print(\"%s: %.2f%%\" % ('AVG Validation Acc ', np.mean(cvscores) * 100))\n",
    "print(\"Validation precision - mean: %f, stddev: %f\" % (np.mean(val_precisions), np.std(val_precisions)))\n",
    "print(\"Validation recall - mean: %f, stddev: %f\" % (np.mean(val_recalls), np.std(val_recalls)))\n",
    "print(\"Validation f-score - mean: %f, stddev: %f\" % (np.mean(val_f_scores), np.std(val_f_scores)))\n",
    "print(\"Confusion matrix:\")\n",
    "print (sum(val_conmats).astype(float) / fold_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f27a6bcda0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_array = (sum(val_conmats).astype(float) / fold_counter)\n",
    "new_confusion_matrix_array = []\n",
    "for conf_sub_array in confusion_matrix_array:\n",
    "    new_confusion_matrix_array.append([int(float(e)) for e in conf_sub_array])\n",
    "        \n",
    "df_cm = pd.DataFrame(new_confusion_matrix_array, range(5), range(5))\n",
    "#plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 12})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "cross_model.save(model_check_point_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
