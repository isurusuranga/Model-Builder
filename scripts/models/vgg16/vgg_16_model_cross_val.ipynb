{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils import layer_utils, np_utils\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "vgg_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
    "\n",
    "train_dir = \"D:/retinal_samples/basian_opt_testing/new_new_train/augmented_224/train\"\n",
    "test_dir = \"D:/retinal_samples/basian_opt_testing/new_test\"\n",
    "    \n",
    "image_width = 224\n",
    "image_height = 224\n",
    "batchsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x0000012562E2A908> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562E2ABA8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562E2A9B0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000012562E2AB38> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562E57320> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562E57DA0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000012562E84BE0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562E949B0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562EABEB8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562EBFEF0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000012562ED5F98> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562EFCA58> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562F13C88> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562F2AAC8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000012562F56D30> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562F69B00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562F7FD30> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012562F905C0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000012562FBEDD8> False\n"
     ]
    }
   ],
   "source": [
    "# Freeze the layers except the last 2 layers\n",
    "for layer in vgg_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg_model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXTrainYTrainSplit(train_generator):\n",
    "    x_train, y_train = zip(*(train_generator[i] for i in range(len(train_generator))))\n",
    "    x_train, y_train = np.vstack(x_train), np.vstack(y_train)\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataKfold(k, train_generator):\n",
    "    x_train, y_train = zip(*(train_generator[i] for i in range(len(train_generator))))\n",
    "    x_train = np.vstack(x_train)\n",
    "    #convert original class labels to the one-hot-encoding\n",
    "    #y_train = np_utils.to_categorical(train_generator.classes, 5)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(train_generator.classes)\n",
    "\n",
    "    #y_train = np.argmax(y_train, axis=1)\n",
    "    #y_train = np.vstack(map(to_categorical, y_train))[:,0]\n",
    "    #np.argmax(Y_pred_for_test, axis=1\n",
    "    folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=1).split(x_train, y_train))\n",
    "    \n",
    "    return folds, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    # Create the model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add the vgg convolutional base model\n",
    "    model.add(vgg_model)\n",
    "    \n",
    "    # Add new layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, use_bias=False, kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(5, use_bias=False, kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-3), metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 5 classes.\n",
      "Found 58 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(image_width, image_height),\n",
    "        batch_size=batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               6422528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 21,139,540\n",
      "Trainable params: 6,424,330\n",
      "Non-trainable params: 14,715,210\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "folds, x_train, y_train = loadDataKfold(k, train_generator)\n",
    "model = getModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCallbacks(name_weights, patience_lr):\n",
    "    mcp_save = ModelCheckpoint(name_weights, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, epsilon=1e-4, mode='min')\n",
    "    \n",
    "    return [mcp_save, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = zip(*(train_generator[i] for i in range(len(train_generator))))\n",
    "x_train = np.vstack(x_train)\n",
    "y_train = np_utils.to_categorical(train_generator.classes, 5)\n",
    "estimator = KerasClassifier(build_fn=getModel, epochs=15, batch_size=batchsize, verbose=0)\n",
    "#Evaluate The Model with k-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print('\\nFold ',j)\n",
    "    x_train_cv = x_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    x_valid_cv = x_train[val_idx]\n",
    "    y_valid_cv = y_train[val_idx]\n",
    "    \n",
    "    name_weights = \"D:/retinal_samples/basian_opt_testing/models/vgg16/final_model_fold\" + str(j) + \"_weights.h5\"\n",
    "    callbacks = getCallbacks(name_weights = name_weights, patience_lr=10)\n",
    "    generator = gen.flow(x_train_cv, y_train_cv, batch_size = batch_size)\n",
    "    model = getModel()\n",
    "    model.fit_generator(\n",
    "                generator,\n",
    "                steps_per_epoch=len(x_train_cv)/batch_size,\n",
    "                epochs=15,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data = (x_valid_cv, y_valid_cv),\n",
    "                callbacks = callbacks)\n",
    "    \n",
    "    print(model.evaluate(x_valid_cv, y_valid_cv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
