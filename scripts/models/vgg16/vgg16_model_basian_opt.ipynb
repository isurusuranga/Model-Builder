{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils import layer_utils, np_utils\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from hyperas.utils import eval_hyperopt_space\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    train_dir = \"D:/retinal_samples/basian_opt_testing/new_new_train/augmented_224/train\"\n",
    "    validation_dir = \"D:/retinal_samples/basian_opt_testing/new_valid\"\n",
    "    \n",
    "    image_width = 224\n",
    "    image_height = 224\n",
    "    batchsize = 16\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(image_width, image_height),\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "            validation_dir,\n",
    "            target_size=(image_width, image_height),\n",
    "            batch_size=batchsize,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)\n",
    "    \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_generator, validation_generator):\n",
    "    vgg_16_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
    "    model_check_point_loc = \"D:/retinal_samples/basian_opt_testing/models/vgg16/vgg16_dr_model_check.h5\"\n",
    "    \n",
    "    for layer in vgg_16_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(vgg_16_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout({{uniform(0.4, 1)}}))\n",
    "    \n",
    "    choice_val = {{choice(['one', 'two'])}}\n",
    "    if choice_val == 'two':\n",
    "        model.add(Dense({{choice([128, 256, 512])}}, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout({{uniform(0.4, 1)}}))\n",
    "                  \n",
    "    model.add(Dense(5, activation='softmax', kernel_regularizer=regularizers.l2({{choice([0.0001, 0.001])}})))\n",
    "              \n",
    "    lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.2, cooldown=0, patience=10, min_lr=1e-5)\n",
    "    early_stopper = EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=20)\n",
    "    model_checkpoint = ModelCheckpoint(model_check_point_loc, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='auto')\n",
    "    \n",
    "    callbacks = [lr_reducer, early_stopper, model_checkpoint]\n",
    "              \n",
    "    selected_optimizer = {{choice(['rmsprop', 'adam', 'sgd'])}}\n",
    "    if selected_optimizer == 'adam':\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr={{choice([1e-3, 1e-4])}}),\n",
    "              metrics=['acc'])\n",
    "    elif selected_optimizer == 'rmsprop':\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr={{choice([1e-3, 1e-4])}}),\n",
    "              metrics=['acc'])\n",
    "    else:\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr={{choice([1e-3, 1e-4])}}, momentum=0.9),\n",
    "              metrics=['acc'])\n",
    "    history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples//train_generator.batch_size ,\n",
    "      epochs={{choice([25, 50, 75, 100])}},\n",
    "      callbacks=callbacks,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
    "      verbose=1)\n",
    "    score, acc = model.evaluate_generator(generator=validation_generator, \n",
    "                                      steps=validation_generator.samples // validation_generator.batch_size)\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 5 classes.\n",
      "Found 55 images belonging to 5 classes.\n",
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from keras import applications\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import models\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import layers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dropout, Flatten, Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.normalization import BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import regularizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import layer_utils, np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import classification_report, confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.datasets import make_classification\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import label_binarize\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from scipy import interp\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from itertools import cycle\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import roc_curve, auc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.utils import eval_hyperopt_space\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'num_layer_choice': hp.choice('num_layer_choice', ['zero', 'two']),\n",
      "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
      "        'Dropout': hp.uniform('Dropout', 0.4, 1),\n",
      "        'choice_val': hp.choice('choice_val', ['one', 'two']),\n",
      "        'Dense_1': hp.choice('Dense_1', [128, 256, 512]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0.4, 1),\n",
      "        'l2': hp.choice('l2', [0.0001, 0.001]),\n",
      "        'selected_optimizer': hp.choice('selected_optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'lr': hp.choice('lr', [1e-3, 1e-4]),\n",
      "        'lr_1': hp.choice('lr_1', [1e-3, 1e-4]),\n",
      "        'lr_2': hp.choice('lr_2', [1e-3, 1e-4]),\n",
      "        'epochs': hp.choice('epochs', [25, 50, 75, 100]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: train_dir = \"D:/retinal_samples/basian_opt_testing/new_new_train/augmented_224/train\"\n",
      "  3: validation_dir = \"D:/retinal_samples/basian_opt_testing/new_valid\"\n",
      "  4: \n",
      "  5: image_width = 224\n",
      "  6: image_height = 224\n",
      "  7: batchsize = 16\n",
      "  8: \n",
      "  9: train_datagen = ImageDataGenerator(rescale=1./255)\n",
      " 10: validation_datagen = ImageDataGenerator(rescale=1./255)\n",
      " 11: \n",
      " 12: train_generator = train_datagen.flow_from_directory(\n",
      " 13:     train_dir,\n",
      " 14:     target_size=(image_width, image_height),\n",
      " 15:     batch_size=batchsize,\n",
      " 16:     shuffle=True,\n",
      " 17:     class_mode='categorical')\n",
      " 18: \n",
      " 19: validation_generator = validation_datagen.flow_from_directory(\n",
      " 20:         validation_dir,\n",
      " 21:         target_size=(image_width, image_height),\n",
      " 22:         batch_size=batchsize,\n",
      " 23:         class_mode='categorical',\n",
      " 24:         shuffle=False)\n",
      " 25: \n",
      " 26: \n",
      " 27: \n",
      " 28: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     vgg_16_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
      "   4:     model_check_point_loc = \"D:/retinal_samples/basian_opt_testing/models/vgg16/vgg16_dr_model_check.h5\"\n",
      "   5:     \n",
      "   6:     num_layer_choice = space['num_layer_choice']\n",
      "   7:     if num_layer_choice == 'two':\n",
      "   8:         for layer in vgg_16_model.layers[:-2]:\n",
      "   9:             layer.trainable = False\n",
      "  10:     else:\n",
      "  11:         for layer in vgg_16_model.layers[:]:\n",
      "  12:             layer.trainable = False\n",
      "  13:     \n",
      "  14:     model = models.Sequential()\n",
      "  15:     model.add(vgg_16_model)\n",
      "  16:     model.add(layers.Flatten())\n",
      "  17:     model.add(Dense(space['Dense'], activation='relu'))\n",
      "  18:     model.add(BatchNormalization())\n",
      "  19:     model.add(Dropout(space['Dropout']))\n",
      "  20:     \n",
      "  21:     choice_val = space['choice_val']\n",
      "  22:     if choice_val == 'two':\n",
      "  23:         model.add(Dense(space['Dense_1'], activation='relu'))\n",
      "  24:         model.add(BatchNormalization())\n",
      "  25:         model.add(Dropout(space['Dropout_1']))\n",
      "  26:                   \n",
      "  27:     model.add(Dense(5, activation='softmax', kernel_regularizer=regularizers.l2(space['l2'])))\n",
      "  28:               \n",
      "  29:     lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.2, cooldown=0, patience=10, min_lr=1e-5)\n",
      "  30:     early_stopper = EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=20)\n",
      "  31:     model_checkpoint = ModelCheckpoint(model_check_point_loc, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='auto')\n",
      "  32:     \n",
      "  33:     callbacks = [lr_reducer, early_stopper, model_checkpoint]\n",
      "  34:               \n",
      "  35:     selected_optimizer = space['selected_optimizer']\n",
      "  36:     if selected_optimizer == 'adam':\n",
      "  37:         model.compile(loss='categorical_crossentropy',\n",
      "  38:               optimizer=optimizers.Adam(lr=space['lr']),\n",
      "  39:               metrics=['acc'])\n",
      "  40:     elif selected_optimizer == 'rmsprop':\n",
      "  41:         model.compile(loss='categorical_crossentropy',\n",
      "  42:               optimizer=optimizers.RMSprop(lr=space['lr_1']),\n",
      "  43:               metrics=['acc'])\n",
      "  44:     else:\n",
      "  45:         model.compile(loss='categorical_crossentropy',\n",
      "  46:               optimizer=optimizers.SGD(lr=space['lr_2'], momentum=0.9),\n",
      "  47:               metrics=['acc'])\n",
      "  48:     history = model.fit_generator(\n",
      "  49:       train_generator,\n",
      "  50:       steps_per_epoch=train_generator.samples//train_generator.batch_size ,\n",
      "  51:       epochs=space['epochs'],\n",
      "  52:       callbacks=callbacks,\n",
      "  53:       validation_data=validation_generator,\n",
      "  54:       validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
      "  55:       verbose=1)\n",
      "  56:     score, acc = model.evaluate_generator(generator=validation_generator, \n",
      "  57:                                       steps=validation_generator.samples // validation_generator.batch_size)\n",
      "  58:     \n",
      "  59:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  60: \n",
      "Found 2000 images belonging to 5 classes.\n",
      "Found 55 images belonging to 5 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 133s 1s/step - loss: 3.7477 - acc: 0.2700 - val_loss: 6.9913 - val_acc: 0.0208\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 2.2015 - acc: 0.3440 - val_loss: 1.7169 - val_acc: 0.2917\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.7533 - acc: 0.3725 - val_loss: 1.5251 - val_acc: 0.2292\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.6400 - acc: 0.3735 - val_loss: 1.8288 - val_acc: 0.2292\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.6151 - acc: 0.3725 - val_loss: 1.4175 - val_acc: 0.3750\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.5691 - acc: 0.3855 - val_loss: 1.3760 - val_acc: 0.4167\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.4925 - acc: 0.4280 - val_loss: 1.3502 - val_acc: 0.4167\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4683 - acc: 0.4175 - val_loss: 1.5587 - val_acc: 0.3125\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.4120 - acc: 0.4360 - val_loss: 1.4092 - val_acc: 0.3542\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.3315 - acc: 0.4675 - val_loss: 1.5031 - val_acc: 0.3333\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.3637 - acc: 0.4710 - val_loss: 3.1283 - val_acc: 0.3125\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3285 - acc: 0.5010 - val_loss: 1.5715 - val_acc: 0.3750\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 127s 1s/step - loss: 1.2855 - acc: 0.4970 - val_loss: 1.3638 - val_acc: 0.4167\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.2268 - acc: 0.5100 - val_loss: 1.3999 - val_acc: 0.3333\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.2379 - acc: 0.5045 - val_loss: 1.4648 - val_acc: 0.4375\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.2409 - acc: 0.5290 - val_loss: 1.5005 - val_acc: 0.4167\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.1659 - acc: 0.5235 - val_loss: 2.0675 - val_acc: 0.2917\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.1451 - acc: 0.5500 - val_loss: 1.3610 - val_acc: 0.4583\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.0786 - acc: 0.5420 - val_loss: 1.2775 - val_acc: 0.5208\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 1.0301 - acc: 0.5765 - val_loss: 1.2305 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.0454 - acc: 0.5625 - val_loss: 1.2556 - val_acc: 0.5208\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.9857 - acc: 0.5815 - val_loss: 1.2777 - val_acc: 0.4583\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.9744 - acc: 0.5705 - val_loss: 1.3477 - val_acc: 0.3750\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.9222 - acc: 0.5955 - val_loss: 1.2796 - val_acc: 0.5208\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.9734 - acc: 0.5760 - val_loss: 1.3091 - val_acc: 0.4792\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.9504 - acc: 0.5850 - val_loss: 1.2968 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.9147 - acc: 0.6015 - val_loss: 1.2608 - val_acc: 0.4792\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 129s 1s/step - loss: 0.9185 - acc: 0.5965 - val_loss: 1.2970 - val_acc: 0.4792\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 125s 1s/step - loss: 0.9014 - acc: 0.6095 - val_loss: 1.2734 - val_acc: 0.5208\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 125s 1s/step - loss: 0.9243 - acc: 0.6195 - val_loss: 1.2689 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 125s 1s/step - loss: 0.8751 - acc: 0.6220 - val_loss: 1.2631 - val_acc: 0.5208\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.8797 - acc: 0.6280 - val_loss: 1.2637 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.9170 - acc: 0.6075 - val_loss: 1.2759 - val_acc: 0.5208\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.9053 - acc: 0.6075 - val_loss: 1.2758 - val_acc: 0.5208\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.8993 - acc: 0.5990 - val_loss: 1.2841 - val_acc: 0.5208\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.9205 - acc: 0.6100 - val_loss: 1.2702 - val_acc: 0.5208\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.8813 - acc: 0.6205 - val_loss: 1.2668 - val_acc: 0.5208\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.8728 - acc: 0.6160 - val_loss: 1.2701 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.8856 - acc: 0.6200 - val_loss: 1.2645 - val_acc: 0.5000\n",
      "Epoch 1/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 4.9258 - acc: 0.2340 - val_loss: 2.3239 - val_acc: 0.2083\n",
      "Epoch 2/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 3.6530 - acc: 0.2540 - val_loss: 3.1206 - val_acc: 0.1042\n",
      "Epoch 3/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 2.8819 - acc: 0.2920 - val_loss: 1.7905 - val_acc: 0.2708\n",
      "Epoch 4/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 2.4139 - acc: 0.3085 - val_loss: 1.6427 - val_acc: 0.2708\n",
      "Epoch 5/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.9207 - acc: 0.3240 - val_loss: 1.5133 - val_acc: 0.3125\n",
      "Epoch 6/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.7311 - acc: 0.3140 - val_loss: 2.1197 - val_acc: 0.2292\n",
      "Epoch 7/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.6012 - acc: 0.3265 - val_loss: 1.4436 - val_acc: 0.3125\n",
      "Epoch 8/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.5542 - acc: 0.3555 - val_loss: 1.4216 - val_acc: 0.3750\n",
      "Epoch 9/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.5240 - acc: 0.3475 - val_loss: 1.4106 - val_acc: 0.3542\n",
      "Epoch 10/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.5357 - acc: 0.3345 - val_loss: 1.4167 - val_acc: 0.2917\n",
      "Epoch 11/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.5387 - acc: 0.3340 - val_loss: 1.7465 - val_acc: 0.2292\n",
      "Epoch 12/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.5438 - acc: 0.3415 - val_loss: 1.4044 - val_acc: 0.3958\n",
      "Epoch 13/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4982 - acc: 0.3460 - val_loss: 1.4277 - val_acc: 0.3333\n",
      "Epoch 14/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4897 - acc: 0.3540 - val_loss: 1.4098 - val_acc: 0.3125\n",
      "Epoch 15/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4852 - acc: 0.3515 - val_loss: 1.4099 - val_acc: 0.3125\n",
      "Epoch 16/75\n",
      "125/125 [==============================] - 371s 3s/step - loss: 1.4679 - acc: 0.3450 - val_loss: 1.3959 - val_acc: 0.3333\n",
      "Epoch 17/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4754 - acc: 0.3565 - val_loss: 1.4009 - val_acc: 0.4167\n",
      "Epoch 18/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4753 - acc: 0.3530 - val_loss: 1.4003 - val_acc: 0.3958\n",
      "Epoch 19/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4491 - acc: 0.3540 - val_loss: 1.4040 - val_acc: 0.3333\n",
      "Epoch 20/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4674 - acc: 0.3500 - val_loss: 1.3949 - val_acc: 0.3958\n",
      "Epoch 21/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4558 - acc: 0.3565 - val_loss: 1.3925 - val_acc: 0.3542\n",
      "Epoch 22/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4335 - acc: 0.3810 - val_loss: 1.3936 - val_acc: 0.3125\n",
      "Epoch 23/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4311 - acc: 0.3805 - val_loss: 1.3931 - val_acc: 0.2708\n",
      "Epoch 24/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4330 - acc: 0.3620 - val_loss: 1.3815 - val_acc: 0.3750\n",
      "Epoch 25/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4602 - acc: 0.3725 - val_loss: 1.4006 - val_acc: 0.2708\n",
      "Epoch 26/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4338 - acc: 0.3560 - val_loss: 1.3800 - val_acc: 0.3958\n",
      "Epoch 27/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4414 - acc: 0.3630 - val_loss: 1.3823 - val_acc: 0.3333\n",
      "Epoch 28/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4395 - acc: 0.3725 - val_loss: 1.3814 - val_acc: 0.3750\n",
      "Epoch 29/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4632 - acc: 0.3690 - val_loss: 1.3868 - val_acc: 0.3750\n",
      "Epoch 30/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4411 - acc: 0.3525 - val_loss: 1.3839 - val_acc: 0.3125\n",
      "Epoch 31/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4283 - acc: 0.3795 - val_loss: 1.3758 - val_acc: 0.3958\n",
      "Epoch 32/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4249 - acc: 0.3820 - val_loss: 1.3703 - val_acc: 0.3958\n",
      "Epoch 33/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4246 - acc: 0.3845 - val_loss: 1.3687 - val_acc: 0.3542\n",
      "Epoch 34/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4491 - acc: 0.3755 - val_loss: 1.3854 - val_acc: 0.3958\n",
      "Epoch 35/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 128s 1s/step - loss: 1.4326 - acc: 0.3840 - val_loss: 1.3995 - val_acc: 0.3542\n",
      "Epoch 36/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4233 - acc: 0.3915 - val_loss: 1.3607 - val_acc: 0.4583\n",
      "Epoch 37/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4215 - acc: 0.3750 - val_loss: 1.3744 - val_acc: 0.3958\n",
      "Epoch 38/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4383 - acc: 0.3810 - val_loss: 1.3802 - val_acc: 0.3958\n",
      "Epoch 39/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4008 - acc: 0.3780 - val_loss: 1.3867 - val_acc: 0.3542\n",
      "Epoch 40/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4391 - acc: 0.3725 - val_loss: 1.3787 - val_acc: 0.3750\n",
      "Epoch 41/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4249 - acc: 0.3790 - val_loss: 1.3787 - val_acc: 0.3750\n",
      "Epoch 42/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4047 - acc: 0.3910 - val_loss: 1.3801 - val_acc: 0.3958\n",
      "Epoch 43/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4058 - acc: 0.3975 - val_loss: 1.3931 - val_acc: 0.3958\n",
      "Epoch 44/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.4258 - acc: 0.3720 - val_loss: 1.3677 - val_acc: 0.4167\n",
      "Epoch 45/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4114 - acc: 0.3720 - val_loss: 1.3810 - val_acc: 0.3542\n",
      "Epoch 46/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3926 - acc: 0.3840 - val_loss: 1.3784 - val_acc: 0.3958\n",
      "Epoch 47/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4138 - acc: 0.3975 - val_loss: 1.3764 - val_acc: 0.3750\n",
      "Epoch 48/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.4147 - acc: 0.3865 - val_loss: 1.3780 - val_acc: 0.4167\n",
      "Epoch 49/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.3675 - acc: 0.4055 - val_loss: 1.3791 - val_acc: 0.4167\n",
      "Epoch 50/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3738 - acc: 0.3955 - val_loss: 1.3762 - val_acc: 0.4167\n",
      "Epoch 51/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3860 - acc: 0.3815 - val_loss: 1.3760 - val_acc: 0.4167\n",
      "Epoch 52/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3448 - acc: 0.4090 - val_loss: 1.3736 - val_acc: 0.4167\n",
      "Epoch 53/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3559 - acc: 0.4020 - val_loss: 1.3683 - val_acc: 0.4167\n",
      "Epoch 54/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3411 - acc: 0.3950 - val_loss: 1.3717 - val_acc: 0.4167\n",
      "Epoch 55/75\n",
      "125/125 [==============================] - 128s 1s/step - loss: 1.3503 - acc: 0.4135 - val_loss: 1.3696 - val_acc: 0.4167\n",
      "Epoch 56/75\n",
      "125/125 [==============================] - 127s 1s/step - loss: 1.3154 - acc: 0.4215 - val_loss: 1.3708 - val_acc: 0.4375\n",
      "Epoch 1/100\n",
      "125/125 [==============================] - 150s 1s/step - loss: 2.2891 - acc: 0.3865 - val_loss: 2.2436 - val_acc: 0.2083\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 149s 1s/step - loss: 1.7888 - acc: 0.4710 - val_loss: 2.2691 - val_acc: 0.3333\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 149s 1s/step - loss: 1.5458 - acc: 0.5170 - val_loss: 1.8641 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 149s 1s/step - loss: 1.4139 - acc: 0.5575 - val_loss: 1.7580 - val_acc: 0.4583\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 149s 1s/step - loss: 1.2821 - acc: 0.5785 - val_loss: 1.7957 - val_acc: 0.4167\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 149s 1s/step - loss: 1.1691 - acc: 0.6000 - val_loss: 1.8541 - val_acc: 0.4583\n",
      "Epoch 7/100\n",
      " 74/125 [================>.............] - ETA: 59s - loss: 1.0696 - acc: 0.6486 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2a7037e4dfb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                                           \u001b[0meval_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                           \u001b[0mreturn_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                           notebook_name='vgg16_model_basian_opt')\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                      verbose=verbose)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    131\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m              return_argmin=True),\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     )\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\jupyter_scripts\\scripts\\models\\vgg16\\temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[1;34m(space)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2230\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator = data()\n",
    "best_run, best_model, space = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=10,\n",
    "                                          trials=Trials(),\n",
    "                                          eval_space=True,\n",
    "                                          return_space=True,\n",
    "                                          notebook_name='vgg16_model_basian_opt')\n",
    "\n",
    "best_model.save('D:/retinal_samples/basian_opt_testing/models/vgg16/vgg16_dr_basian_opt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation of best performing model:\")\n",
    "print(best_model.evaluate(validation_generator))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "print(\"Real hyper-parameters:\")\n",
    "real_param_values = eval_hyperopt_space(space, best_run)\n",
    "print(real_param_values)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
