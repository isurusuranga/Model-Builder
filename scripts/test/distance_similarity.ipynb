{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import unicode\n",
    "import h5py\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Input, Dense, GlobalAveragePooling2D, Merge, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from imutils import build_montages\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define functions to create the triplet loss with online triplet mining.\"\"\"\n",
    "\n",
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm = tf.diag_part(dot_product)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.to_float(tf.equal(distances, 0.0))\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def _get_anchor_positive_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i and j are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "\n",
    "    # Check if labels[i] == labels[j]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check if labels[i] != labels[k]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    mask = tf.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i, j, k are distinct\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i, j and k are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def batch_all_triplet_loss(labels, embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # shape (batch_size, batch_size, 1)\n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
    "    assert anchor_positive_dist.shape[2] == 1, \"{}\".format(anchor_positive_dist.shape)\n",
    "    # shape (batch_size, 1, batch_size)\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\n",
    "    assert anchor_negative_dist.shape[1] == 1, \"{}\".format(anchor_negative_dist.shape)\n",
    "\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "    # and the 2nd (batch_size, 1, batch_size)\n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    mask = tf.to_float(mask)\n",
    "    triplet_loss = tf.multiply(mask, triplet_loss)\n",
    "\n",
    "    # Remove negative losses (i.e. the easy triplets)\n",
    "    triplet_loss = tf.maximum(triplet_loss, 0.0)\n",
    "\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets = tf.to_float(tf.greater(triplet_loss, 1e-16))\n",
    "    num_positive_triplets = tf.reduce_sum(valid_triplets)\n",
    "    num_valid_triplets = tf.reduce_sum(mask)\n",
    "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)\n",
    "\n",
    "    # Get final mean triplet loss over the positive valid triplets\n",
    "    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)\n",
    "\n",
    "    return triplet_loss, fraction_positive_triplets\n",
    "\n",
    "\n",
    "def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "    #print(pairwise_dist.eval())\n",
    "\n",
    "#     # For each anchor, get the hardest positive\n",
    "#     # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "    mask_anchor_positive = tf.to_float(mask_anchor_positive)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(tf.cast(mask_anchor_positive, tf.float64), pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "    mask_anchor_negative = tf.to_float(mask_anchor_negative)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - tf.cast(mask_anchor_negative, tf.float64))\n",
    "\n",
    "#     # shape (batch_size,)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "    #print(triplet_loss.eval())\n",
    "\n",
    "    return triplet_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(data, labels):\n",
    "    pos_label, neg_label = np.random.choice(labels, 2, replace=False)\n",
    "    pos_indexes = np.where(labels == pos_label)[0]\n",
    "    neg_indexes = np.where(labels == neg_label)[0]\n",
    "    np.random.shuffle(pos_indexes)\n",
    "    np.random.shuffle(neg_indexes)\n",
    "    anchor = data[pos_indexes[0]]\n",
    "    positive = data[pos_indexes[-1]]\n",
    "    negative = data[neg_indexes[0]]\n",
    "    return (anchor, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_features(image_paths, labels, hdf5_path, feature_extractor, image_formats=(\"jpg\")):\n",
    "    # image_paths = []\n",
    "    # for image_format in image_formats:\n",
    "    #     image_paths += glob.glob(\"{}/*.{}\".format(images_dir, image_format))\n",
    "    # image_paths = sorted(image_paths)\n",
    "    db = h5py.File(hdf5_path, mode=\"w\")\n",
    "    features_shape = ((len(labels),), feature_extractor.output_shape[1:])\n",
    "    features_shape = [dim for sublist in features_shape for dim in sublist]\n",
    "    imageIDDB = db.create_dataset(\"image_ids\", shape=(len(labels),),\n",
    "                                  dtype=h5py.special_dtype(vlen=unicode))\n",
    "    featuresDB = db.create_dataset(\"features\",\n",
    "                                   shape=features_shape, dtype=\"float\")\n",
    "    labelsDB = db.create_dataset(\"labels\",\n",
    "                                 shape=(len(labels),), dtype=\"int\")\n",
    "    for i in range(0, len(labels), 16):\n",
    "        start,end = i, i+16\n",
    "        image_ids = [path.split(\"/\")[-1] for path in image_paths[start:end]]\n",
    "        images = [cv2.imread(path,1) for path in image_paths[start:end]]\n",
    "        features = feature_extractor.extract(images)\n",
    "        imageIDDB[start:end] = image_ids\n",
    "        featuresDB[start:end] = features\n",
    "        labelsDB[start:end] = labels[start:end]\n",
    "        print(\"Extracting {}/{}\".format(i+1+16, len(labels)))\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(hdf5_path):\n",
    "    db = h5py.File(hdf5_path,mode=\"r\")\n",
    "    features = db[\"features\"][:]\n",
    "    labels = db[\"labels\"][:]\n",
    "\n",
    "    return (features, labels)\n",
    "\n",
    "def extract_embeddings(features, model):\n",
    "    embeddings = model.predict([features, features, features])\n",
    "    return embeddings[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a,b):\n",
    "    return K.sqrt(K.sum(K.square((a-b)), axis=1))\n",
    "\n",
    "def triplet_loss(y_true, anchor_positive_negative_tensor):\n",
    "    anchor = anchor_positive_negative_tensor[:,:,0]\n",
    "    positive = anchor_positive_negative_tensor[:,:,1]\n",
    "    negative = anchor_positive_negative_tensor[:,:,2]\n",
    "    Dp = euclidean_distance(anchor, positive)\n",
    "    Dn = euclidean_distance(anchor, negative)\n",
    "\n",
    "    return K.maximum(0.0, 1+K.mean(Dp-Dn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetFeatureExtractor(object):\n",
    "    def __init__(self, model=\"vgg16\", resize_to=(150, 150)):\n",
    "        # MODEL_DICT = {\"vgg16\": VGG16, \"vgg19\": VGG19, \"inception\": InceptionV3, \"resnet\": ResNet50,\n",
    "        #               \"xception\": Xception}\n",
    "        # network = MODEL_DICT[model.lower()]\n",
    "        self.model_name = model.lower()\n",
    "        self.model = self.getModel()\n",
    "        self.preprocess_input = preprocess_input\n",
    "        self.imageSize = resize_to\n",
    "\n",
    "    def extract(self, images):\n",
    "        images = self.preprocess(images)\n",
    "        return self.model.predict(images)\n",
    "\n",
    "    def getModel(self):\n",
    "        model = load_model('C:/Users/hp/Downloads/data/model/top_model_vgg/final_model.h5')\n",
    "        intermediate_layer_model = Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer(\"block5_pool\").output)\n",
    "\n",
    "        return intermediate_layer_model\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self.model.compute_output_shape([[None, self.imageSize[0], self.imageSize[1], 3]])\n",
    "\n",
    "    def resize_images(self, images):\n",
    "        images = np.array([cv2.resize(image, (self.imageSize[0], self.imageSize[1])) for image in images])\n",
    "        return images\n",
    "\n",
    "    def preprocess(self, images):\n",
    "        images = self.resize_images(images)\n",
    "        images = self.preprocess_input(images.astype(\"float\"))\n",
    "        return images\n",
    "\n",
    "def concat_tensors(tensors, axis=-1):\n",
    "    return K.concatenate([K.expand_dims(t, axis=axis) for t in tensors])\n",
    "\n",
    "\n",
    "def get_small_network(input_shape=(None, 4, 4, 512)):\n",
    "    model = Sequential()\n",
    "    model.add(GlobalAveragePooling2D(input_shape=input_shape[1:]))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    #model.add(Dense(128, activation=\"relu\"))\n",
    "    return model\n",
    "\n",
    "def get_triplet_network(input_shape=(None, 4, 4, 512)):\n",
    "    base_model = get_small_network(input_shape=input_shape)\n",
    "\n",
    "    anchor_input = Input(input_shape[1:])\n",
    "    positive_input = Input(input_shape[1:])\n",
    "    negative_input = Input(input_shape[1:])\n",
    "\n",
    "    anchor_embeddings = base_model(anchor_input)\n",
    "    positive_embeddings = base_model(positive_input)\n",
    "    negative_embeddings = base_model(negative_input)\n",
    "\n",
    "    output = Lambda(concat_tensors)([anchor_embeddings, positive_embeddings, negative_embeddings])\n",
    "    model = Model([anchor_input, positive_input, negative_input], output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list=[]\n",
    "labels=[]\n",
    "train_data_dir = 'C:/Users/hp/Downloads/data/train/'\n",
    "cat_root = train_data_dir + 'cats' + '/'\n",
    "cats=os.listdir(cat_root)\n",
    "\n",
    "for cat in cats:\n",
    "    image_path_list.append(cat_root + cat)\n",
    "    labels.append(0)\n",
    "\n",
    "dog_root = train_data_dir + 'dogs' + '/'\n",
    "dogs=os.listdir(dog_root)\n",
    "for dog in dogs:\n",
    "    image_path_list.append(dog_root + dog)\n",
    "    labels.append(1)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = extract_features('C:/Users/hp/Downloads/data/similarity/similarity_db.hdf5')\n",
    "model = get_triplet_network(features.shape)\n",
    "nSamples, nWidth, nHeight, nVolume = features.shape\n",
    "embeddings = features.reshape(nSamples, nWidth * nHeight * nVolume)\n",
    "loss = batch_hard_triplet_loss(labels, embeddings, margin=1,\n",
    "                                       squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 4, 4, 1200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 8192)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-e511ebd0732c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_check_point_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#X_train, X_test, Y_train, Y_test = train_test_split(data, targets)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# model.fit([X_train[:,0], X_train[:,1], X_train[:,2]], Y_train, epochs=10,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#           validation_data=([X_test[:,0], X_test[:,1], X_test[:,2]], Y_test),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \"\"\"\n\u001b[1;32m--> 603\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    666\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \"\"\"\n\u001b[1;32m--> 668\u001b[1;33m     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n\u001b[0m\u001b[0;32m    669\u001b[0m                     \u001b[1;34m\"Use `if t is not None:` instead of `if t:` to test if a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                     \u001b[1;34m\"tensor is defined, and use TensorFlow ops such as \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor."
     ]
    }
   ],
   "source": [
    "# data = []\n",
    "# for i in range(len(features)):\n",
    "#     anchor, positive, negative = get_triplets(features, labels)\n",
    "#     data.append([anchor, positive, negative])\n",
    "# data = np.array(data)\n",
    "model_check_point_loc = 'C:/Users/hp/Downloads/data/similarity/vgg16_cats_dogs_dup.h5'\n",
    "targets = np.zeros(shape=(1200, 256, 3))\n",
    "callback = ModelCheckpoint(model_check_point_loc, period=1, monitor=\"val_loss\")\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(data, targets)\n",
    "model.compile(optimizers.Adam(1e-4), loss)\n",
    "# model.fit([X_train[:,0], X_train[:,1], X_train[:,2]], Y_train, epochs=10,\n",
    "#           validation_data=([X_test[:,0], X_test[:,1], X_test[:,2]], Y_test),\n",
    "#           callbacks=[callback], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train[:,0], X_train[:,1], X_train[:,2]], Y_train, epochs=10,\n",
    "          validation_data=([X_test[:,0], X_test[:,1], X_test[:,2]], Y_test),\n",
    "          callbacks=[callback], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(embeddings, squared=False):\n",
    "    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.diag_part(dot_product)\n",
    "    print(dot_product.eval())\n",
    "    print('##############')\n",
    "    print(square_norm.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 15 11]\n",
      " [ 4  8  5]\n",
      " [13  4 13]\n",
      " [ 5  9 12]]\n",
      "[[427 211 320 312]\n",
      " [211 105 149 152]\n",
      " [320 149 354 257]\n",
      " [312 152 257 250]]\n",
      "##############\n",
      "[427 105 354 250]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.random.randint(16, size = (4, 3))\n",
    "print(matrix)\n",
    "\n",
    "calculateDistance(matrix)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 15 11]\n",
      " [ 4  8  5]\n",
      " [13  4 13]\n",
      " [ 5  9 12]]\n",
      "[[338 195 221]\n",
      " [195 153 132]\n",
      " [221 132 145]]\n",
      "[338 153 145]\n",
      "[[  0 101  41]\n",
      " [101   0  34]\n",
      " [ 41  34   0]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.random.randint(16, size = (3, 2))\n",
    "print(matrix)\n",
    "\n",
    "dot_product = tf.matmul(embeddings, K.transpose(embeddings))\n",
    "print(dot_product.eval())\n",
    "\n",
    "# Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "# This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "# shape (batch_size,)\n",
    "square_norm = tf.diag_part(dot_product)\n",
    "print(square_norm.eval())\n",
    "\n",
    "# Compute the pairwise distance matrix as we have:\n",
    "# ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "# shape (batch_size, batch_size)\n",
    "distances = tf.expand_dims(square_norm, 1) - 2 * dot_product + tf.expand_dims(square_norm, 0)\n",
    "print(distances.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims:0' shape=(3, 1) dtype=int32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.expand_dims([1, 4, 5], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims_1:0' shape=(1, 3) dtype=int32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.expand_dims([1, 4, 5], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
