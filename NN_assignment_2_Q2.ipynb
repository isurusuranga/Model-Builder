{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MLP with automatic validation set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score_per_cluster(data, N):\n",
    "    return (data['y'].value_counts().max() / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "#dataset = numpy.loadtxt(\"D:/Neural_nets_course_Dataset/pima_indians_diabetes_data.csv\", delimiter=\",\")\n",
    "dataset = pd.read_csv('E:/Academic/Neural Networks/Assignment_2/iris.txt', delimiter=',', names = ['a','b','c','d','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d  y\n",
       "0  5.1  3.5  1.4  0.2  1\n",
       "1  4.9  3.0  1.4  0.2  1\n",
       "2  4.6  3.1  1.5  0.2  1\n",
       "3  5.0  3.6  1.4  0.2  1\n",
       "4  4.6  3.4  1.4  0.3  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:4].values\n",
    "Y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilaize to very small random values\n",
    "weight_matrix = np.random.rand(3, 4)\n",
    "#weight_matrix_norma = preprocessing.normalize(weight_matrix, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84175922, 0.30500036, 0.48831798, 0.88720764],\n",
       "       [0.87403121, 0.72834783, 0.14212033, 0.70981784],\n",
       "       [0.58188005, 0.95242927, 0.77550592, 0.99208439]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_indexes = []\n",
    "alpha = 0.3\n",
    "\n",
    "for i in range(500):\n",
    "    cluster_indexes = []\n",
    "    for index,iterator in enumerate(X):\n",
    "        # calculate the distance vector\n",
    "        out_neuron_vector = np.linalg.norm(weight_matrix - X[index], axis=1, ord=2)\n",
    "        min_index = np.argmin(out_neuron_vector)\n",
    "        # add cluster value for each tuple\n",
    "        cluster_indexes.append(min_index + 1)\n",
    "        # retrieve Wk vector\n",
    "        Wk = weight_matrix[min_index,:]\n",
    "        # update the Wk vector\n",
    "        pwx = alpha * np.subtract(X[index], Wk)\n",
    "        Wk = np.add(Wk, pwx)\n",
    "        # add Wk to original weight matrix location\n",
    "        weight_matrix[min_index,:] = Wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cluster_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity score for cluster 1:  0.0\n",
      "Purity score for cluster 2:  0.3333333333333333\n",
      "Purity score for cluster 3:  0.3333333333333333\n",
      "Total purity score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "temp_dataset = dataset\n",
    "temp_dataset['cluster'] = cluster_indexes\n",
    "\n",
    "purity_score_cluster1 = 0.0\n",
    "purity_score_cluster2 = 0.0\n",
    "purity_score_cluster3 = 0.0\n",
    "\n",
    "#purity score for cluster 1\n",
    "cluster1_dataset = temp_dataset[temp_dataset['cluster'] == 1]\n",
    "if len(cluster1_dataset) != 0:\n",
    "    purity_score_cluster1 = purity_score_per_cluster(cluster1_dataset, len(dataset))\n",
    "\n",
    "#purity score for cluster 2\n",
    "cluster2_dataset = temp_dataset[temp_dataset['cluster'] == 2]\n",
    "if len(cluster2_dataset) != 0:\n",
    "    purity_score_cluster2 = purity_score_per_cluster(cluster2_dataset, len(dataset))\n",
    "\n",
    "#purity score for cluster 3\n",
    "cluster3_dataset = temp_dataset[temp_dataset['cluster'] == 3]\n",
    "if len(cluster3_dataset) != 0:\n",
    "    purity_score_cluster3 = purity_score_per_cluster(cluster3_dataset, len(dataset))\n",
    "\n",
    "print('Purity score for cluster 1: ', purity_score_cluster1)\n",
    "print('Purity score for cluster 2: ', purity_score_cluster2)\n",
    "print('Purity score for cluster 3: ', purity_score_cluster3)\n",
    "print('Total purity score: ', purity_score(Y, cluster_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
